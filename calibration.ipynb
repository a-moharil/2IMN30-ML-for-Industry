{
 "cells": [
  {
   "attachments": {
    "wafer.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMAAAADBCAYAAACZgL+iAAAMPmlDQ1BJQ0MgUHJvZmlsZQAASImVVwdYU8kWnluSkEBCCYQiJfQmiEhHSggtUqWDjZAECCXEQFCxI6KCaxcL2NBVEQXXAshiQ+wuiopdFwsqK+tiwa68SQFd9pXvzffNnf/+c+Y/Z86dufcOAOonuGJxDqoBQK6oQBITEsBMSk5hkp4CEtAB2oAKyFxevpgVHR0OYBls/17e3QCIrL3mINP6Z/9/LZp8QT4PACQa4jR+Pi8X4kMA4FU8saQAAKKMN59WIJZhWIG2BAYI8WIZzlDgKhlOU+D9cpu4GDbEbQCoqHG5kgwAaFcgzyzkZUANWh/ETiK+UASAOhNi39zcPD7EqRDbQBsxxDJ9j7QfdDL+ppk2pMnlZgxhxVzkRSVQmC/O4c74P9Pxv0tujnTQhxWsapmS0BjZnGHebmXnhcmwGsS9orTIKIi1IP4g5MvtIUYpmdLQeIU9asjLZ8OcAQbETnxuYBjEhhAHi3Iiw5V8WrowmAMxXCHodGEBJw5iPYgXC/KDYpU2WyV5MUpfaEO6hM1S8ue4Erlfma8H0ux4llL/daaAo9THaEWZcYkQUyC2KBQmREJMg9gxPzs2TGkztiiTHTloI5HGyOK3gDhGIAoJUOhjhemS4BilfVlu/uB8sa2ZQk6kEh8oyIwLVeQHa+Nx5fHDuWBXBCJW/KCOID8pfHAufEFgkGLu2HOBKD5WqfNBXBAQoxiLU8Q50Up73EyQEyLjzSB2yS+MVY7FEwrgglTo4+nigug4RZx4URZ3XLQiHnwFCAdsEAiYQAprGsgDWUDY3tvYC+8UPcGACyQgAwiAg5IZHJEo7xHBaywoAn9CJAD5Q+MC5L0CUAj5r0Os4uoA0uW9hfIR2eApxLkgDOTAe6l8lGjIWwJ4AhnhP7xzYeXBeHNglfX/e36Q/c6wIBOuZKSDHpnqg5bEIGIgMZQYTLTFDXBf3BsPh1d/WJ1xD9xzcB7f7QlPCR2ER4ROQhfh9hRhsWRYlBGgC+oHK3OR9mMucCuo6YoH4D5QHSrjDNwAOOAu0A8L94OeXSHLVsYtywpzmPbfZvDD01DakZ3IKFmX7E+2GT6SZkdzHVKR5frH/ChiTRvKN3uoZ7h/9g/Z58M2bLglthg7iJ3FTmLnsRasETCx41gTdgk7KsNDq+uJfHUNeouRx5MNdYT/8Df4ZGWZzHeqdepx+qLoKxBMl72jATtPPEMizMgsYLLgF0HA5Ih4jiOZzk7OzgDIvi+K19cbhvy7gTAufOeK3wLgwx8YGGj5zoXDvX5oIdz+T79z1sfga0IXgHPlPKmkUMHhsgsBviXU4U7TB8bAHNjA+TgDN+AN/EEQGAeiQBxIBpNh9JlwnUvANDALzAeloBysAGvBRrAFbAe7wT5wADSCFnASnAEXwRXQCe7C1dMNXoA+8A58RhCEhFAROqKPmCCWiD3ijHggvkgQEo7EIMlIKpKBiBApMgtZgJQjq5CNyDakBvkFOYKcRM4jHcht5CHSg7xGPqEYqoZqo0aoFToK9UBZaBgah05CM9CpaBFagi5D16PV6F60AT2JXkQ70S70BdqPAUwVY2CmmAPmgbGxKCwFS8ck2BysDKvAqrE6rBk+52tYF9aLfcSJOB1n4g5wBYfi8TgPn4rPwZfiG/HdeAPehl/DH+J9+DcClWBIsCd4ETiEJEIGYRqhlFBB2Ek4TDgN91I34R2RSGQQrYnucC8mE7OIM4lLiZuI9cQTxA7iY2I/iUTSJ9mTfEhRJC6pgFRK2kDaSzpOukrqJn1QUVUxUXFWCVZJURGpFKtUqOxROaZyVeWZymeyBtmS7EWOIvPJM8jLyTvIzeTL5G7yZ4omxZriQ4mjZFHmU9ZT6iinKfcob1RVVc1UPVXHqwpV56muV92vek71oepHNS01OzW22kQ1qdoytV1qJ9Ruq72hUqlWVH9qCrWAuoxaQz1FfUD9QKPTHGkcGp82l1ZJa6Bdpb1UJ6tbqrPUJ6sXqVeoH1S/rN6rQdaw0mBrcDXmaFRqHNG4qdGvSdccrRmlmau5VHOP5nnN51okLSutIC2+VonWdq1TWo/pGN2czqbz6AvoO+in6d3aRG1rbY52lna59j7tdu0+HS0dF50Enek6lTpHdboYGMOKwWHkMJYzDjBuMD7pGumydAW6S3TrdK/qvtcboeevJ9Ar06vX69T7pM/UD9LP1l+p36h/3wA3sDMYbzDNYLPBaYPeEdojvEfwRpSNODDijiFqaGcYYzjTcLvhJcN+I2OjECOx0QajU0a9xgxjf+Ms4zXGx4x7TOgmviZCkzUmx03+YOowWcwc5npmG7PP1NA01FRqus203fSzmbVZvFmxWb3ZfXOKuYd5uvka81bzPgsTiwiLWRa1FncsyZYelpmW6yzPWr63srZKtFpk1Wj13FrPmmNdZF1rfc+GauNnM9Wm2ua6LdHWwzbbdpPtFTvUztUu067S7rI9au9mL7TfZN8xkjDSc6RoZPXImw5qDiyHQodah4eODMdwx2LHRseXoyxGpYxaOersqG9Ork45Tjuc7o7WGj1udPHo5tGvne2cec6VztfHUMcEj5k7pmnMKxd7F4HLZpdbrnTXCNdFrq2uX93c3SRudW497hbuqe5V7jc9tD2iPZZ6nPMkeAZ4zvVs8fzo5eZV4HXA6y9vB+9s7z3ez8dajxWM3TH2sY+ZD9dnm0+XL9M31Xerb5efqR/Xr9rvkb+5P99/p/8zli0ri7WX9TLAKUAScDjgPduLPZt9IhALDAksC2wP0gqKD9oY9CDYLDgjuDa4L8Q1ZGbIiVBCaFjoytCbHCMOj1PD6RvnPm72uLYwtbDYsI1hj8LtwiXhzRFoxLiI1RH3Ii0jRZGNUSCKE7U66n60dfTU6F/HE8dHj68c/zRmdMysmLOx9NgpsXti38UFxC2PuxtvEy+Nb01QT5iYUJPwPjEwcVViV9KopNlJF5MNkoXJTSmklISUnSn9E4ImrJ3QPdF1YunEG5OsJ02fdH6yweScyUenqE/hTjmYSkhNTN2T+oUbxa3m9qdx0qrS+nhs3jreC74/fw2/R+AjWCV4lu6Tvir9eYZPxuqMnky/zIrMXiFbuFH4Kis0a0vW++yo7F3ZAzmJOfW5KrmpuUdEWqJsUVuecd70vA6xvbhU3DXVa+raqX2SMMnOfCR/Un5TgTb8kb8ktZEulD4s9C2sLPwwLWHawema00XTL82wm7FkxrOi4KKfZ+IzeTNbZ5nOmj/r4WzW7G1zkDlpc1rnms8tmds9L2Te7vmU+dnzfyt2Kl5V/HZB4oLmEqOSeSWPF4YsrC2llUpKby7yXrRlMb5YuLh9yZglG5Z8K+OXXSh3Kq8o/7KUt/TCT6N/Wv/TwLL0Ze3L3ZZvXkFcIVpxY6Xfyt2rNFcVrXq8OmJ1wxrmmrI1b9dOWXu+wqViyzrKOum6rvXh65s2WGxYseHLxsyNnZUBlfVVhlVLqt5v4m+6utl/c90Woy3lWz5tFW69tS1kW0O1VXXFduL2wu1PdyTsOPuzx881Ow12lu/8uku0q2t3zO62Gveamj2Ge5bXorXS2p69E/de2Re4r6nOoW5bPaO+fD/YL93/xy+pv9w4EHag9aDHwbpDloeqDtMPlzUgDTMa+hozG7uakps6jow70trs3Xz4V8dfd7WYtlQe1Tm6/BjlWMmxgeNFx/tPiE/0nsw4+bh1SuvdU0mnrreNb2s/HXb63JngM6fOss4eP+dzruW81/kjFzwuNF50u9hwyfXS4d9cfzvc7tbecNn9ctMVzyvNHWM7jl31u3ryWuC1M9c51y92RnZ23Ii/cevmxJtdt/i3nt/Ouf3qTuGdz3fn3SPcK7uvcb/igeGD6t9tf6/vcus6+jDw4aVHsY/uPuY9fvEk/8mX7pKn1KcVz0ye1Tx3ft7SE9xz5Y8Jf3S/EL/43Fv6p+afVS9tXh76y/+vS31Jfd2vJK8GXi99o/9m11uXt6390f0P3uW++/y+7IP+h90fPT6e/ZT46dnnaV9IX9Z/tf3a/C3s272B3IEBMVfClf8KYLCi6ekAvN4FADUZADo8n1EmKM5/8oIozqxyBP4TVpwR5cUNgDrYyH7j2ScA2A+r1Tyo7Q+A7Bc+zh+gY8YM1cGzmvxcKStEeA7Y6i9DnXoTcDCsKM6cP8Q9vAUyVRcwvP0Xd/56GrqEE1gAAACEZVhJZk1NACoAAAAIAAYBBgADAAAAAQACAAABEgADAAAAAQABAAABGgAFAAAAAQAAAFYBGwAFAAAAAQAAAF4BKAADAAAAAQACAACHaQAEAAAAAQAAAGYAAAAAAAAASAAAAAEAAABIAAAAAQACoAIABAAAAAEAAADAoAMABAAAAAEAAADBAAAAAON7UWgAAAAJcEhZcwAACxMAAAsTAQCanBgAAAMYaVRYdFhNTDpjb20uYWRvYmUueG1wAAAAAAA8eDp4bXBtZXRhIHhtbG5zOng9ImFkb2JlOm5zOm1ldGEvIiB4OnhtcHRrPSJYTVAgQ29yZSA2LjAuMCI+CiAgIDxyZGY6UkRGIHhtbG5zOnJkZj0iaHR0cDovL3d3dy53My5vcmcvMTk5OS8wMi8yMi1yZGYtc3ludGF4LW5zIyI+CiAgICAgIDxyZGY6RGVzY3JpcHRpb24gcmRmOmFib3V0PSIiCiAgICAgICAgICAgIHhtbG5zOnRpZmY9Imh0dHA6Ly9ucy5hZG9iZS5jb20vdGlmZi8xLjAvIgogICAgICAgICAgICB4bWxuczpleGlmPSJodHRwOi8vbnMuYWRvYmUuY29tL2V4aWYvMS4wLyI+CiAgICAgICAgIDx0aWZmOkNvbXByZXNzaW9uPjE8L3RpZmY6Q29tcHJlc3Npb24+CiAgICAgICAgIDx0aWZmOlJlc29sdXRpb25Vbml0PjI8L3RpZmY6UmVzb2x1dGlvblVuaXQ+CiAgICAgICAgIDx0aWZmOlhSZXNvbHV0aW9uPjcyPC90aWZmOlhSZXNvbHV0aW9uPgogICAgICAgICA8dGlmZjpZUmVzb2x1dGlvbj43MjwvdGlmZjpZUmVzb2x1dGlvbj4KICAgICAgICAgPHRpZmY6UGhvdG9tZXRyaWNJbnRlcnByZXRhdGlvbj4yPC90aWZmOlBob3RvbWV0cmljSW50ZXJwcmV0YXRpb24+CiAgICAgICAgIDx0aWZmOk9yaWVudGF0aW9uPjE8L3RpZmY6T3JpZW50YXRpb24+CiAgICAgICAgIDxleGlmOlBpeGVsWERpbWVuc2lvbj40ODA8L2V4aWY6UGl4ZWxYRGltZW5zaW9uPgogICAgICAgICA8ZXhpZjpQaXhlbFlEaW1lbnNpb24+NDgyPC9leGlmOlBpeGVsWURpbWVuc2lvbj4KICAgICAgPC9yZGY6RGVzY3JpcHRpb24+CiAgIDwvcmRmOlJERj4KPC94OnhtcG1ldGE+Cj7pbnwAAEAASURBVHgB7b0JmGXJVd8Z7+XLPbOy9n3tquqtelOr1d3qbqSWxAySkDxmZj5kCTH+jLH1DdZ88qARSAbGY/g+bOOxweLDhmEwxgZ6hDCyAYGk1tpa6IaWWr1V77V17WtWVe7bm//vxI337rt579vyvVyq61S9vPfGcuLEiXNORJyIGzd3d887it0dfW6uOOdy7josmANiYrHoXGe/c2fOOff2H8y5T/yzvBsYyrmZaedyeZWg+KYA3HPC3eXc8IWi+6VPzLmnnyi6Neudmx1rCuMbMhPsz6shxmdHXaEr3+u69SvC2esq0BqBkKB2FvSTpA/25t22LR2uf7Vzc1NiPArQBNBoGKg5NVO+27n+zqIb6J61MnoKUq4m8TZByjWQpSgF6JDRn3WFopsz4Z/T1bO4WfN0DfClVVUQC+f0g5OzupmS4PfoN60eAAVolsNBATpzOTc1rZaT0Srq31wxRyu2ivprGk9OZgSe+f9zTnYKgLWVfy3g+p8FcQCu5iSs+bzYLsHXRc+Bz82hJj9KBE4PNCk4w3NzeN94uTzXrneci9DyzAmAVtrogNNjvv63WQ5cV4BmObfE+a7b+9Y0wHUFaA0fr2NZoRy4rgArtOGuk90aDlxXgNbw8TqWFcqB6wqwQhvuOtmt4UDkBm0NsmWPpZob5o02q6zGi2oNeY3x6Q2jAOaH70xvWVyKc7PpcU2FamHKWd8qxAhMFaFpyJ0pPKQvCr8t5rAogHOVNYEOXatClNaI0Upoh8giqEGY02KebRpoMN9yTf7GUACEBoHs1S/IQdQiCIFWxJ2biAJackEoTTQ9tiqyWVrPqqdcaNcvn2MpnwwR4ryuEujqEIiIrj1CpTwNKSAlwit+Vn71EldC7DWvAFgr9s5MXXLu2LAsfaxVaMMZ/dbar3WbCUzELkYFTVJKtnT6zQxeKINM8cR9/Ao2yb3RTx2sw5qManOC2MbgrDT0srIgAL70+vJvVbLuNaJjUvRcAzPIa1oBEP5uSffR4879T38n537kA3mXV41DF16UmHV1zLrXLgy6X31ym+vRc17WlL01C4WCpLVnIu869oy7XNfrkhgRE405sLoFDVkujHW5zz63041NdrqOPKpQu1zydkjwJiSA595WdGvfIgXXc8borqIa9Bwzc9o00THn/uVbXnfbh8bc1GyH9SjWE6QUb4qoMsNo6799ds599veL2uCnvU0yKPQiKxmuaQXAXHb2OfeKWmjrDufuuV8Crq3EoRtgLJ3TrsqeU91qzLWuX1axAyFpxCRmtL4Ny6elcJuvSmKlgYbTxMkEPZ+bcxMzHe6zh4fc90e63UYphPa3eRXwycqYo2dQgBf6tMnUbdvuXJeeEV6S1IKC8szNav5QmHW333vG7Vo/5orT4kE9mUmjcp58Iude1s0u9arTdEDXFaAW25cwHuGgkQQzGutMakemtr+aMUZiEJxuxU9N6WZagwoJf1E/L6w+X9N/ERgkdUYF6DJPQhUmeXTbRUDP7JzrllVmB2m9AO1TqlMDWTwN6gEYQE1Nqq7qRSaFA6UCDzFpUIrTDXyUTWl47pCGdzmEXds9AByOWhUrl/yhGyHMm0EStahZwBM3rUlJVTxBUyJiHB1R2kYUwKhslFaUO6pwqHfpWqXa8WJIb1UhMPySdauCa7lFrTwFiLdGLW5WpK14qLScoQErk9TCvqB4G3MvCMNCM1dWNs6CcE8JpOI5npr5himOhj/JibDVK45AaUuQFV5KsPg3K0sBGDPUM9sLfMRVEhujhkYMV58sNgam9SojA6aFX4UX1KVf9LxwxI1goHRA0+3oNoSEK7Hx+/BsYfpDPr3t6QpyoxaG9Cz+BgXhOqthVVHDpHlIQKQ1hDD/4nE5wMpQADiLIF/hhoFLA2D+QqU3LwwmS/fhx02O1oq/Dx2as4EyMpKCyZcFEX6OYb5MK5fnQFwGgpYH+7pRfU+P6m6m3CitWlrgyowE/KRS9r7gHN7XYI8ChlvFS71ga63ky4mjlQVbpVCqPT8ynnDR7pe/AsBZXB2XZlz+gfUuf8cGmZjQHLX5NCue369Fruf1Tu5/fkrWXs/B0IOlILfn6ZEu1y9B4LkVLlComhWyQeE+Lg/PI0/tk7sV3L7dKQdv05WpDjc2XXC4TK1KZGwjzOL1wvrP5d3nnt/h1vdt9m7ROsukTlvuOeu+8YeX3Jz5P6lJGXKqxxde2ua+dHSVW981Jx9AkHKlk6927uA5N/cNnRSwWszA7iwDWBkKICqxKbnN/a5wYLPuxVB4H/hbjZFKpwMZ3EuyOp97zvOdkRTZuY7qZp9ckNvUYITxawWAp0sKcGa80/3S8xvdFZ71w/jRmY0rwRbF36BygxdGwW0FaLKhjwTzt19b447KJdov3tTqU8mn0Y47JpfpY+8ddT9wo1YV5eL1vVkgWYjUo708tNqd79/otvbMygMXGkhKV+iQq3lc/D2jezVoyecb8i/NdfkrQOAh/JG7sIjvr0ExRej6hOdB+e+8AIAsAoXjrZwqNVaIWPgVwemUVbynb2a+rqpceoSJNpRbD+U3SkBvgbcQWQNIooMn3FYpwIzcVsVx0c0L/uQvgVKprtOTOmlBbVTUAiMKYEkUVaSyuIQJAeEygeWvABWMEvOaMJc0AqwfyzB11kgV5bTugbYeyxDydpZbqwaToqkeOYRG0qEAlxBoDL9+9mJ+sgKyLjm1Dy5dDgPw1gZKhKH0XE+p5FkcWGEKsDCmJNtrYdjqz71U5daisF66SBd+tXDWircy6y24FrIWxC8/BRBzKnzLWG0G68AyYpwnqL1/a1W3mi1dSN6atUoUzGOpvERcBa4oEZ2BTYRKmRgiKaxa3gpErXtYXgogBrBzUyc1lh09MIXZo8AYtwRM8qUv/l/03uqcUjReI+Y2WVA1rzLh0WkaJLgx2Y16hygkHpEogNGrRQ8oQu0cgDrOal4xp18F4pCgjddlowBYgLwWVy5fkMtSP7buhzaiMUf0u1OulHVi1mK4DNvI87pRn5KXZgS+mNT4bNwi+GKV26yNTaFz9LHlv2eU97LyMnYPfAx5kb3N8nzF48o5a90Jm7w9RXXTuD0DsJM1p/C0mQWpOlT4JTXis7rvOVxJk5YW3M36DWnn7pxc1hUjAIW3E5aHAohDBVmFs2ed+/GfyrkHH87ZMYLB+sHcTr3C9N3LOff/iYm4Nekxr0VA2Kc12ezVjs1/etdpt7FvyvvqkV4BzpROuU+vag3h95/f7F4f7XK9EmbCyStHmW6K7lPKu23VuLY7a0dqlBfDwVbq8Zmc+6ODm93By91uSEpUz+5Xegx2rH710AZ3+OJg6voBCvH02UG3XTtsp23NwUiWJ0wHBWsj4offn3P3/FiHypPySC2F0kAeUvfX3y66//Dpotu0SXXgoN8QGaVp12VZKADWv0Mm7XnV8tbbc+6h96iVMAtRw8nc0Opu6oWc+7ff0AssGhLR4NcaUKW8Wp4Fq4J2h96/86zbskbd3izNFFUYXsjFODrR5f7s1Q3ulavy5aMAUV4tF7pZWeJ7d5xzuzbqrZxprdWWLLXy6r2DCSnP1w6vc5cv9ri1nfEFq2yOUnqPsn/++Cr30pEh16v7ZBPwfKvwGT2BXIWxDfv7Gt788wdy7gcO6CG+hkA6acjY6Kw7KIzb1PUzFFqsXn5ZKIBYYNxk2DMl//KcLAAHypZ6ADGpS+7/KSkFS+8Rb8l1TYFkyoArAjChVeLZKb2roJdWwnCDleoubesYn+r0Vr+CG2UMkzM6m1p5J2YK6gE8x3j/gZXv8Skpie4ZljQCYNncNet2yFhlCeiU8KbNL+i1aT+s+3S0A4OywdOlLoit6lKNTLykbQcsvQKERtCVsS1C7w9/LStA6N4ZG/qmbAcrlg9OqyN8kOCGX1AAqORlmrwsOcDwsMwVcvIM7xRDuggHYcT6vCEVoY0BQ5upKrNvX/p8nFBL+8XbFuEvtbcy+hpFeePVmo+uZSFLowDWwlEduA+/atXK4my1PNdMXJxh1Sq1OExqppS0GiD8yZ6E4TAv3tvL9/Gqap4QRgTx4IXeL74CwAnGMcEFATexKAxVdfF/NUUKHLNAOGWRb5w/qq+37tFVzyYAUTjDGSDN62IRxi/4phQktXwBl89r6ZbJH+q2RbR0D/peotT+EX0zGjoxfGq1h2hxFYBGYSfYMJ1dRYcnH5mf9+oVbaXpsJfGg8YXOdOkY0Zj1vJnPCK+XLMX6l7Iy62oehdMFcQ8hfnvDejDDhrAkyZrCNShiTI8K7B9QXwDSMvL9x3iL0OkpJC1k5kitSow5zulFIWDznGgRtgsSj5OrLlTv9VtcJMurgJQ2mWNa9+x0eW3Daqb0w5PtaI1hGT83lHnvitGzD2tTVdMlJQcoOEKarjnzw04fW0odZLlU678v7yZwOR0Wu7LL7y81a3tnZZrU0IcVQ1RxqsyJk/KhfGCXo7Ha+QjyUuP0CmT/+grm93Gk2vlUpUbVGEAf3GJTmqN4KTcp6vNBRowW5K2/YlITMXPHO/mW3PukX+Vd11apIgrJve4SZ96suj+2+/576FxJEtUpVR8jQQungLAZytt1uVvWusKt2/RiQQxd4CiddyMe1SG67cer/T2kJWXiXbL3UejJfoOxVw7gDDwrgD++3/z3CZ3EQFQ9XQxkOwbLwbElF1yObLlOsSR13pNKcCvv7DRnRWjWPQK/IKPjDZxYe5W3rjyKLitAN0lQmMlQe+siLrpQM7dIhd4HIIi5DQ87tLhAb8oBfjvtF5EbxHi4umbuV88BShRp0rKjVecUa3ZHmt15o8X7NW6vRd/aAX4eF6wCNauIvoafKDGe9Toe6UMnklBzD0vEAA8MiE0yYJdes9gT1ZeMZ0jTbLyJnEtxjM9fhKMPv3Rupo/tEMJWiX4oawlUACKViOi+rSlmawoTBcslG0bJ6gCysOAiuBr+IHTWvwMlkrCrAD+Ph4SYsJ1IXkDjsW8lsQgVij6Kx23YRt1hR2thrYogO3sQ5LjQB/IBLgOqNawdWRvKkk15i4FPVRiIeUuJG9TDGxHJiqRaBhzk6q3qHCTSq6a9Q61XAEgsHOVfjo6oKK7UmVsIYtlbhsQtoNjzeFkYsibW1lCw7CL4cZ1aJ4DNDmyzEq2P926DlzK4PMorbqIPbr06t3uAruDozh6jmlWl3XQacpryjULaa0CiCh2dJ4+7bSvIwuK7n4pAUvjdBJLLVaUPyGvyAvyqjAMDQ0F9cQh+Oyc3KRJI41xHZrjALt5O7W/qaNzyib5pdMxSujgblwakHCeddVeIW1vcof1NKntpLhLSR3gFt1sbNJF2joFEK05aeaYnLj/wwdz7v/QC6czbDMkXARiX7k6ueW+r11VT0nawgkZBC8FYPnHJPx7Byfdj2+/bO5H86RExMBk9s6c0skOX3x9yLwxvi5LQe3KLBN+4by4Xd67Z88MSgl2uRl5uNLG/Kk1RITkF77ad9X95qeGXUe3TJTCwsEIHYo79FLRfekPi65/vcSrQRdpyxSA4Q1bmp+TAvyL9+bcO7Wjc0orGOz9ABAmmJFTP/Wfvpdz//lp596hF1+y3tMlT7uhS8OeIzN590OrJ9yH3vSqg7fh6BDKto1nndPu2ZMb3R8fW+XWqtVQmjeKJ6pV/McOrpMCfO7IGvdbOo2CqSDyUBPE6zUyQE+MdrjPPHDSfeS9w9pIx4A/yq1Lp4zu17805z4tBbhPQ+8ZvUvSyMdOWqYA8cqEytGDhXvi7Z4w3eiy5FCiTYQW5zqsx7WjPEoMFpXqEmwlesmpXdkEwGvOSRqq0xESastaxeYuXvyJ1jtigmMjJCWMy1mpTQOCGte2KECpTKiJCDah5z6iMFaPUvLlduNJ5W9E9HIjcIXRw4IcQ8xGgN6WxcAA5liR8Jj8hHBdm5WnaIAS0Lf4Gqcqfq9iAu0tLrGl6BIktxT3dWSNcsC3BnOHau1S99wiKr75HgAJ5heoCc911itkqzP5IiQLleHqoXwXQq5fl44DvjVCKyXpsIVkVre1Z8YO540nqLJO0JwCQEW3RDiem75EExI/wdGDjavV5VX0MSzdy52o/MtFAaCD6jDOp3tm4hs2GJi/WuFh67GSXYdF5gBtYzKldrE1BG0MZMwPIEc2pJLZ36HnHp3fyKmLthAbEzC2Uk9lrBPERdiQ1vwTKLqo4+9K26zKAo2/t4sVCb3D260BXHmFLqJIpzHjDx4BT4zImuW2IQHFsxbB5rNu+afZddgpBpe9DNJehXfpBXXIvQ6LzwHaSMtGapv4GgJ0qEVoFG2Uy0sjXtbtZXkWz+tKm8ah2jpBYwoANVj0q5qVP7TB5TZo1xqzFGSGEhV3tz6c9pRe1J59URuutGsvOSZjH/rLF/vcHZwcwKxoCQH/9Hotch3X6dBffmWHvaNT0QOoVijrkeE+N6B7+M3vOiweB1iIvFsu1IPn+t3Qi7u1NRwBLLcCawQX3Kj7rX9y0RXkxzbrH4tnneDVF4vui3KTDqSsE+Tu63t3sSffL1vOmS4mxtm1o2ze5row5zo/esDl9wsjuzpjUs7tVQn2WQ3K0K4yqWW0rKz2CFdaXDnV4txRYw4qPqWjQrAccfYSx9hyjQLXiublQK/IecMBbTIqmTqtRUvuA+BW/e54h/uNO8+5f3jvSxIoubLVSEEcuWed4GtfnHPv+/Cce/AGDYVsnQC3aoc+TTVSMYoPeOu8Ig6UxrUMFMoK72oVnAV0GpW5slK2Pxw6OLdmj3zNWUAMNF+HpeEAA4U+Sf5+GaE4dEv2xtUwDGGJwWCF+QHpwn0pFwkS0NgQKJHZHkPJsTgIbtTfG8u+6LdUoZ7DoRadsOsFljiQ1kYa3djrkiUBJ3VcHrmPIk324wkjZaiuAPEMJVKu31znwDLmQNLKR88Mbxmd2Dg3miUzX0hXABJyDBhjg5IS6IaNMPikCAwDLR5XOFAtutM0oJr0Du34gEZaecs9jG3jcvB5YUohNutgrJSk7QmiGdVmcaB9dyugT1upOSiPz8VxRCSnD6YrgIS8eIHpH4OZNJAK2SGUaXErKwxesR36xekOG+fDLFMF/UH4mSBzJub17dBers6KTyfkMCjZxiBwunK7R69isn+H++UCvEP8oigaeSpnblJOmQCw5ZUKgDTwG9Ms+c1rXG6dXqmOD+bN6qtqvG83wOvWABlWJiDsCP+2vmn3/o0j0XZo+cKi3oAFMLZDnxvrdN85228Mo7bLqXEXi/PUm2Z/eNOI2zEYDuydz4nnzve5V692mxJkmc/FoplyGPZs2pJzv/T3865Pu0XZ7DinQI6VOT+s9q0gBgHnDWT1+YV7t7r8jZGbM03IUR96ATizQoHu/Ki2Q//g2nH3kftf1AkLeHviK8FazNNC2DPaDv3FM/vdGvEHpXkjeoSYcJ6V5X/P/jPu4b0ndG5pp3gRVwAMx6z7nb+5yX1Dh+7e3Dvn+AzTUooH4szL9pw2cdMtNnY3eZ2TUe/p7nCvHs4nFABBDhRTY/LgSwphcUGP1z0evoLuqRbV4NqhJWsOq+M+NBsv8eQVDiuugeqqZgsD5o4dZgTyGgJVfh8AzHwfzAwE9wQsE0ARCmHAIpqYA+TlpufVysoeAIJDSzP04Z4+JDhUl1OtoHWBEKoaqkmVbSUYy+b/W905cOo6eKG2ETF8EkMquELPqR/iwvxyuUH8JRkUgApwna8AgfJ47eL3If4auobqYSmQfXvWHxoTTQib466hKjddFXgUJN/4FDDZcMgzz9gWwpfJ1eiOaAn30J+tADUIZ7gQVuCSSdljY5YiGRE9M6Swr6Mn4iGo2uFXdK/kS4NaedPyEEY+MPqdn/QAWDBCozDEP/SAFtrYHzAx1whCE3ITTm+Dl2mlgPHKrLznyXzS8Y/Oq2r7q6cyreeGNkqbT1gFDTaosbTJSXBFsuwHGHFRE6Krsc/vhNQg5/3PngxXGHkvK++w8qIIcUD41ipvX0peko7LY3NBk9agwcm8q+WuHGhgzw44/bi2qB2f07YbtIOJW0QXgp9TeCcffY4XVuc9aFhDOC3XIVcUGDyEU1f2Q60trJwBFpN/eAFPusSbykkwFZuVf12fXNLtYgE0UWZ3QaVK+AJ/q5XPJDgnZ0+nHTxcLWVGHI35lnXjbgMHtyIkSlcuuOgOX+lxR7XDEiVguBWAdFi8u9ZMuM39U/7QVwIF5Iehx650u0Nyo8XPvCQJCyy7B6bcO1ZNKK0vk3wASgcTTqjMV5S/5KP20Zl/oX2VhPDSZMG9cHatLfCE3aDQgwKwFfrQpQF9lM4TSng9QGr4NKQvqrxVrkMWj+AF4eCgrhxw+5x2xk5JsYPSKWpZAjyGV8e0M/bl0+vdlF5ODwpAfaxFdAr1ubEut5a6EthmoK3YqEiZB8+sE2P9McDVh6zeDdrd1eGOntcp2RW7QTnCATcouz3/0a1lN2jUOlgwevMTMpu/+fbX3Ft2nHF8igdGeCYoXlbgkaf2u595ZqN7sG9WO+684PAXi//aVM79u4eOuLfvPS5XWleZiapMQRr5X5/b4376u1vd3b2zbiLKiyI9p11/v3DHaffBN70mXy4HhqMGHmBEt6zSl17e4T7++E53gza2IXz1AknHDWN6DjbAdqu0BlCaR+m8BPxtEv5Pvu2gG5Qi2EnN4hX0dsmSnrzS5372q7e4M2rAHvVciyE06TWsLxR+T4sLnDySBsRjKCRFiwoYFsxi3e0jbc7rzZnx8+cbnwNQSYYNWLROuUlRCL9w5MUxL2Fl8UgnnZcEVLcloHskb0ENrrNfSwpAAqw4eWGwx0aoB06H5lhwExQKjVUX61TQ0ImxNviTeT2G7L+k75P1yAYxt1GkQmYWXzR1U1fNtjrUX2MsEHTo7VJ4vB7Z5S+PGKgtYKiqcdjaZnHppeWqt18lPUUJTAftrV9Tk2AKpBEZIszYmNkLDzKir1J5C5fBJJ9XKfViA+fez+FPVj6YyzgA6whR9kxYBCxJUOaM8s1Zz1AeBpGHsTtDGvAn8wYcWVfKR3GzgJhmrLPVSzRBF3WFV/Si0Jun/ro2rq5ZVC5OOIOEan2hycXikFIqxbdfGGCWglNuaEml1i442tsMbkqqmkGGRnhgBBYtbB0goz3rCjlp4EnQ3ygf6T0g0H5Yk1aVkMrSl/L4nAg9ozR+Hn+Ess4Ledq1uhvqBI/4GAg0Qm/gU+PqWmel2pSsGUPQJlJKaH37ibE1wafBcGPvaHPaoiUAEUC4+qcG/iYyJh4bQORpWEj+hgqrN3GMoNhtvbmvp2sxB4K6NDUEIjNaxM+6c54DgYTr3s/HQ2D5anmtG/L5Qz6u4APTWl269CvKahKOVwcPBLGU59PpIYJ42IBUmyMPTbOtS8Dyou0agoTCQsZFuNKnlX4q3+519TRDALVqPbBOY70lPLUiKJx7f8Ubp/9veGhKAWwSjD9Y52biHYkPgVxeH2aTEI5mNCyTVL735cyXrO9X0SAC/vJBOFrrpYm8vYN7hbG+IgY1WXx+HJXSNlzlk/SQpQQoBL5pRO37E/rAniY540pCu/Ojq1slHPwqc5ZQtOWGyTmLhV2qV4fcqQyBqK+nd1Yu1q5K3rWQinPT+vq65hnxfUzwguEljb5O6w/hQ50tLHbFoWpYAWDgoDh5+FK/dkR7fzAWNgAfYj4tf/yNUgIUJQ4IBD7iY5d73SunN8iFKn9CpACkI++0muhn9152vWogrKQPL7qHWQDTVxMPKl+yBwCvHbWiNJ/cc7m0/uBnFV4Iz413uoPDPf59HsPa3j8oWrd4cEWLYC+cW+P6VZ/yJNjTe3aUr8DzEbvWWOMg4PD07ZvG3Cq5Xun5PBdRfimg/nLSwgsXe92lqYJ5zqD1jQoNrQMEJsHQKTFS7xmkQq8YbRtJU2LJG3zJ3AfmM2x5bCrvPvuWE+79txy19QWbOCoNioCf/8uvbHcfkp//To5UiTJy4QWMr2qd4HfvPOM+cNdrOh0Y/6wiBChLj7Y0P350i/voYzforH9fZijXp2rfX8rBRx0m9jyHemN96EFbBWwTmcJLpt75N971ktu3frjCyMALet8RrU/8ymMH3JdODbgd3bO2bblVNKwEPOYG1TrAaDPrAFSQRuRTnJ1ZjaeGyBIwwvEj40+OQ6dybFfjFdSddMpHLhSl3sEaTmFsxV2nNP1yY4UvtoCvR13ANvl0cTH6dQIwewpQHg68sr3+Cg3CR4rFAMrrxeecBVS0ZeB5CkbWGDr1q+Qjw08ZIGkjBioxkmwZFSsJkR8CxaXC87BmHar5g2v5gm1F2T7eHArm27h+D5DljXzmuWiNACHGz0/DYu3Nh8u4J1JA/LnsHwKS6wTk5bQ35gF1Vs3wtOoPZfo1hjK9Hrd/bpf7lXUHDEdYp4EOE3jd2PqLnuNDV0/TG+8v88WKMYE918GHhVgPryBeHMM4neWwMTUYoQx9zE8eWUfsZ2isCdEbPDqkhXx1DrzFaWCT6igfAVaKnslPkiiZpV2MP5TnhdwoiRWZfI5FteDWG5kkH/0kPAwtW1DMikdRKOibXhwoagKNpEXT4nY2jzVOgnX0AL0IrhVcWXpcaENMuAY0lc88xXP5VMwzGGLxtS8mhAFIuRCFDniauSZ3xMZxLKR3MCMjg0IPGFzShPFMzzCfO+WS09onxBre8LBMrrQkNGdBtfYtDF+S9VROEsGWwJjVGifyFll4zkLeTDjbmpPvi3IsyUuanNE9t6NUGv5V4e8T/jmVxTNA/VAM5g6LDZR4RVvDAy3x8unJGNaFni8el30PRl8vvGI5TYa7NGcK2zwQXu6ZH4Cf5zQYE03svk2TqV7mFsqbkTUNXVvDoJH54LhozgJ2FuORS4PCnW/JuUHOuEXwxG1Do91o5/pzjpOemSylZ01DVzsMpu/QVujV3TO+4cVMgHK2SUBX9ci3FAmnRbTkT871ds64H9kw5vrNVEQNqHIQhFGO+hitcpZjS2ioRMJQE0Hco+3dnWocrHJYpGKIQnscF02TGe8/VGLzT6FXoyM/cbVX6wwzyh/btqwymC+xDZsf7yOkKcENqybdQOdsRftQArLBztVLk1pr0UMr5QL8jQL00EuulSxt6sMvCRAaURa172W5e0+NsmvZElT8KXzqX+bdzm0FNzkVFmrEFCH53Wec+4/HnLYW++MwKnI18UDZdPdHpakfP3DaPbTnZMV2aFBCdg/+8tnK9QHimgUEfEbrDTdtGHb/+l1XK9BgeXGvHjyz1v30Y3u1voFChDF7RdKWPsCHEY5jGZh0P/PgK25D36RtlaYHhias9+XJTvfLj93knr3U64Y0yalnOEQa6puT1f+VJ3bJnkWCkEL9lJR+tXgdvGm0D3BVmvn37zzu7tp2fv7JD9rq/gdP7XX/7qX1bl+Pd5+GfD734v5lh8Axuc7/1g0X3Y9pm7wdjisSAk3Unpdevn1ks/vE47vcbrnPWWqNz3MLa9bn3NBGNbodZe4tIj7rXvUKE7qJDKZCWgOs0A7o8KTB3inXJzNCg8UBi5Q2JIinafSeErokVCyuxYFyOqQAq+QLt0U7EgbuxRO2/B6Lr1VaWeDVPdNuiBeLorfrjCYNXeA7Lkueq4/Y5xNHNUb1kg/XLKAniFeVe9LDh0Hxw7ePV6gSDikAPAyr7KXwJbpBwXGK9MhArBUPc3KPIz8MG63u4l1e7TsoeQs0x+sM2QXO8C/q58/yF1OUAiSz4kR8Gb1VdWSog2vOabGKVdCkleI5SWQrykaQ/PyijI1hR17+XHMVEkzlq4pNOe+C71QUloiXZBB+WxFW3aFTYmfP1ohN0mNrAJY3cBNs4V7s98jnVYMUvn30mVtTSoxGNDQWfXjgaMPlAaJFBHO6A7TmZFTi1bJhplzp1CeL5oL582VplM7aP1j8kha1uKYQaGQi6Pole4B6iis3Yz2pfRryJJXNi4RX+jjj6se6wJQiCl7AAxu66Bk6/X0wBIQ0Tp0f25M3QPw+hMWusWJ8+3g6TB6i8oNxapyaWDktvfVzOWTVeCY6vbr6QuBg4GsWzRL7CEKKcA3hLb4uFD35wy9OWiXeyqd4uvh9faniOa7fX2sciLz+ra0WViNpbxjHspWhR9bOBE9dqfdH8xTMDxmD5ZtPEzj4Nl/5OBY/OqYb7AWFAMtnHhUrJQq0GG/p7XZZ/IFQ/ns+4HjA8tJtG1/gT0T3opDrC7Oi7JyKQIdR4flYVPuRLM7VJG1pbZ9Mk/Zs7ZYWUTUsoktpKnlmrLWc1AWeZtHcFgVI8/PTFbEH6KB2MyOwTi66Ln2dPfioQz153ZFxZhrMaoz3vNx36xSNnxqgQfCXvypvANCpbcdOHpZkjW1eo/H2cgEajK6bY0byorlLg3KEZ05/8vjvNUM2hbCKUMvFAYYQnbZdnTUE0SbeGnDRblyMD56ULEhr+6y0IRzUHHyAr76xmnrvGDRxyABgwo5oCBHGhbUQ6pNFc8sVAEGr8PMbGSIokskbJJxXtFf9xMUh81GHcSXEMwEcwiuitQDv/SA0kmXFDXRPuQ9vGJX7zlccAaLCKNSOQe2C1P6ioxdXKS+CXu5JwNXfNSNPgWb7ywCgjEbjOJTXL/e7sanOikkwbtAr8uJMaGK3WItOQfBY/Dw10uPWXxy0naQYLuJsGiz+DouuIbGXdk4CyrNTR9cMidfEI4dAPClh8WdSUcbFiYI7qy3rGIF6gXblRSloOjI8KMQ2exHG8igDg3hG286HhBf6KssubXyot8jsdNCNIB6Rn/9/v/WMe9sNnCAcO/ZE8aTh2JT/8txu93N/s93dGDv6hIY+Iiv+z+4+5d538zGdO6PDSBQGoCQz8hrdvfWi+9WNwyXGWqT+wAj8+d84tMV96C8P6Cx/pY9qimV5SVul/9f9F93fu+c1eQPYCuFpCfkX+4pwsPLMOwr/52P7rCdI0gD5+Or7lC7LY5PMs5DniF0aSubcbzy1TZZ/i4Ql8v4IMfG037QW5jZ3+vUDngPQ9mdk2D5+4JR7cNdpKU/y9OiQsny1MtV2nYUp9+jLO90/eXKb26+jQmi7QE859fw7tsRDy9eOr3LfOn3rvATggEa8fxtlNINMxBO2tAegMDalDYioQfll437+QAwKUFDn/rRWFHfo7bFRWUHieAXy2KR3/wXBjxNKmh5pc59WKJOAAnTwPV9Zg9d0lv9At6wrGQRzUoAj41ro02JYuRktasn/MNQb0YJXFiR99VnpWh0+Nq01hIh/SdxY6zQrTdtznM2g2meVVmVnNdQlbTWwWPEAXz0yM6oA8DQKuEAntOKdBdCbRUtLFYAKQYZ9PEZEJf38Vjkb5xXdVi2osAWgK7It9ABrldkzN50NtguUNYQKYOLIfhff/fGqH1sMPO9lXVTGeoUx5FhuQE2MViMs0Ofrx1PaMGMx6gDP/DCi3AME4wFNgdIkLQw88bkXozUe3vADUzVgLtTFWoyQNru9gt7H5i0VZUElZeMaFU0ZRLdUAaioFUu5Eji0Lu57N1aYIObcZZvssiBjoeoTclrVC4SmU2toUwSZER/zAQAcDBnCsIErp9OlY/R5wl9jkvCQNkIXotp2DXRmlbhYdMQr6BUvWXLyOZ6jfI8Bo81921Or6pwn1tLqGhS+eo5yWeGO9EGOQliZn9XpbrkCUFxwSTE0iRdv92bBizrTkYOJpPWRaqL9bIf2ghzPVa5SrTuYDQ6sfWAieG1XZZXMlEYPxCuFaV0lViw0ThINedPyJNO143l+o7ejlMZwWg+hdk+2PVjiDo8KrGos+MjLTqHtQvuFdNXaIKRp5tpSBaASjNALpa246nzszS9Ii5RBrjTujsudebv6vbFoSM8cgM8V+VPfktUnf21AIE4ySRMjwzvDjMleU1m2vJ+Bgka7rHwFLYfTAMnJElaNYUEaMKGe1HAvq4tNy9OKMAyFH6q0AltrcMALTgQJ27DjvT8loBT80oDw19QGuySRdmRLgt3si2rHMLalCgDN2kWtnYwFNzza43cTBsGJKpTLF+Smn3Nv05bbddpROGA9gh//3Sct6Na25aa2Qwt/tybJd8kNtzHmBcK3/FC+w/V3c7poGvP9i+J7lI+X+bHmccuKoE1roj6iLbVJoEoI4Rq5bkmHEqSVkMzXzDNlgduuukFpR8RnvqfQrjIboRO69G6Vtf0ltf1U4sQPeIMDg810pK0ETuGecQ9qd+xGDjYmMkrEBd5OyIiNaaLb6rrmjnzvfcVdO/rd5KQss0wdExntqXP//vGb3K+/vM7dEm17haZ6AILXaX/2gPmC1TgxisF9RRb/7x4449687YKblLchWAmSYUEGlW9QwsowqhFg+DMifFflVSFnYDLlIyy9Ug52XiaBtPjbL4379wHieel2OdPnhbNr3M99Z5dtlw74mHgNy+13z/ox97/d/5rqO2u9DL1Fu3oDXzYTe7ZLF9z//Z197gUd9bKqzu3Sybq3+tnaXjwO7xJAL7zghZQTOq/pH7/ppHvnvpNypZbbHRqQAbxhV2RkkJHQdsT5Nph2X3llm/vlp7e4XdrZybwpnoZ0jcCCT4WoVhgCdEb+7dfljuQ+APeMx7+u49H/kRps09CItmB3y+Ii9mWo1k2WU82/g1Eoz5BZ+sp4ygZv3LKHFDAS9+r2VbwXVwkoYV6Hf10Y1Rn+UVSoE1eO4mIr7jbl7ZcCzEmRgkJXYmrdE/Xo0Opm/0SXeZCoU62JZutKr44JnvDCzOsxmuBvn6T6y2Md7h9qwS9NdOEzRo8F0CT4Npiy7c7DEpU9SjDfEZ7MVf/z/H69/ryZKdF4PjQfBxqJDuwWCQwW2ak781uA46l0r3yJrIkE2Y8IQ3LLczw1FikNYPJ0NBSLx7Oi3M0yOoIdj4juCaMu1IPt4+DwztiUxC0KQgEolzL9kAtmLh/ArdsTs89Qx2LkFlm/0raKFHLT2g6jxnC4U0NYTvvAgLYaygrQQuRUuuze8yRbs6mMyagBcZNiLbOEspmKWhWarEcaHQizp7HsVYKupMiRl3R032l4mqlLVh6qF2gijQnJPIqycrc/HINQ2ad7F+UITEsyLkZOWtthNMni3aTecNZAE8NY/TaQUjCCJZRYQWwvxNvCgT1VR9JMLEICfjSbMpPMssZtBvEC8hhTrf6VSKCPL4tzxUuFBQouT+YAdgivBD8M24J1rsTS2iesfigPzKKuqQLwqKgKqYA1zsLKHKeRXg488I1PGXEP7dQhu/RKkkxGaAMF96snSfu4IvJko4rKrKUn6ln2IIHLu+BpwwJuq7y6eXNfUTkaVP+oKFaczK0EBN6+9ChXaUEFzJsD0KTUdhEBpYQHSTCBFp32Irk8QQMy77w4ZAIiPo1rGILbluMG7cBfiUYjwpEsr55naIKe4AJttgfgTbQsqGaEGGLONCAVNGWHBO6Y+EeJHfCZlXoT6SwKfLiJAav8agPk8aL4zal25iaNZQVXtZ4X5WAncQB7HVX0MGQtjMv3iotpSlj96cUaRyslfvN6PzYXENdzZRo0ocKnVOaEvCg5XkkLIEJRRHy+iwkoOsIMoPCe8d5KaZouP794oYkyKxgs3lmvqYT6VJk0R4qgutj6gYQKA2L5QdZKEFIaGQWQl1cuQSkfYSqtqfK0HqMmngcE5VVGpitaAsyxMo0A5fSJV9OybBOimw11afu95uFUMahKl1QIwacN5qQM1DtOQUc1eoU0pzZipzB5qB9eoDmZ/yJrUj/16Y8Xh9avdrMzejA18qgP62uL57RFtdVKgLDdMDilkxD0Irg4g7UBEL8rYsz/fPMZ9/ANp+b5kS1Ri//Y0Eb+51fOD7nf+u4ue1/B94C+IKwOBmLP6jH33+87o57Ld7WwiV4Kq39qpNv92cubNVRqo/DH6o1A0MtgvV6SCxT66Mo9F2MJU25JRz4Wqn7+vmNu1+oRKTfHpvj6UHcE7fef2en+Qjsst+nl+CmkV8Aer3MyBJ+466S7b4dc2HbcikXV/GO8UpmPv77OPXFytetHiGvm8gmg+YoMzAPbh9292y/a+9MmxUSr0rxP8eTxde6ff3+L2ywlQ74CL5DdE9ph/EGdGvE/HjihCN8/F6VB3d0d7sjRy67w9TP9rmtq0BVntPxgCuALXqNuCm9OQOZDF/6X8eALl7vdE5f8UeXg58cbXU9M5tw7dg6LjnrZszB6rG5q9HGtH/zOyQG3R/XHkoejQvjYxre1lfoXta7BScsFSQpzApQW5clJeXK51e5R8XBSPuxeNWzWgVILo7ScW2wy4aHzWaNFJRPecnTVO3oLbCAWfPeaEbdr/SU3F//Kp5BPS4JWd291V9QEO5Xa5/CicVVhW3WO0e4NF91cbKt71ULBAa+0W/fJ1ze4Tx8bdPdrbSkcg1kr75Da4LHRDvf27VfcXpVbFL3BaPo2mLavbV6GNiFDX1E4AN7gOl3fO+P2q67h2BQUIC8FyF0dcQX2U/fhw5Y1YyHM5/ZfMI/weGwt+gvOQblCVyPkdF1iMVaNvTi3ybb5LQeEtx+sFBFEte+QtVul8rGCjPGhq1vd0pt0D02sbBaVkJ2upKcbZukM99wW8XCObd5KR14vaO2iX4VHCsiWDfjZOGgIKsuPMFGvMGyjXlOqGHXA4oMbTgTAGuMSjucLcdWu1tNGRu1W8Xmz9vxPiY9x3Kn5lQDDuEs9D9TMidZp0V0C2kbhtEFWL2g0SyuoZ1wBujs6jAcFJhRYLRrU01iTrFL5zd7QTXkhA0MQF203QCcMqf/bLP5684VSuPJN4h71AAzFoA+6cjIloxFNWB0ERKyyjpKVAQQHbvHuAZNhPukU8oKhbQARCwTqE/+BjgEArZGFHbbE83BfL4RW5qs/DKvgWVY5JZxKg1E5qTYgNeXRBnEpCW1AaBaUaEaJSBTVnQER7b3kUJMRi0Vh1J5colu7hntPRiW1Ic5fQzMvFsH1l1MPffGaxesVv6+/xETKCHlslJ1IkP5I2aF8UsTv03NUhtZKX2BMzvBj1rQCKn0WLHStzJVFLfzJSlehdJnmgkygNOsUMTIRtaBHUPqTo7EwZQsIb1jR9lYnFFHJFfIy2WKVE/cuz3EgxPcK8dDyfTV/fDlV+h0b4bIgDS/DAXNqiE54zFjZeB0hwU8C34FemUbqH+rEPcORkCeeL8qeefFl+fI89vlJ4bGfolbGUe560dJIbxPHQHlGq+qVo872XA4r0B11mD+bfSwk5+cL9Hf2uCh/cL+aAGo+goeF+zjwFBooHr7Qexp1XOPIHtUdr2wYnuUZAmn8Wbm9wlhaKhKaOOmafUB0sLiPk1YuWY9SZt1U88fH06XdN4KXOjKXsa3bGuuagsjRUdCxauChHgihDREkKJxabUMVxt9R+BXdkyaX0T5pNBKGESAPRgJjIBTzgLnVTMqAhAMeT6tcv01+XraaAQztqZ+9MWZeINVVzzlZA7btFyT9UnNEb1YRnjT+oi024K1ZROsScOaPvd+pl8En5fqKNzANxPqAnyS3rkww2dhSPDD7jTBQd0GRBtPciYWYMkBJGUJes8ZqZCQknkIk22G18bCQ2/gs/sexh7haV6NQSpsGWXjts7MSfvzprMVMyEXI6dNeAfychskpPvO8ti4XkY1IJmAJJ0bgJp1IaZ8kHdQXOrjCz+4ik05dFZjKC/GacpNAG0hKTYGScbWeKYceD9cvJ4CX3KCyBt25DjshO/fNr32guH3bgJuy06GZ2mENiu6RZ3e6Pzk65LZp+ykT5XYDzMKrsaN/2m3R8elxS083fGmqw71n73n33puOKy694RulkWrR+GNyYZ4Z0WnAgtBo4R46+rTLdOPA+DzLhfAjDKeVl0YOebmSj7Nqjgz3u1/WSc18uM97ieRTVwLO4N85OOn+8b1H3DodIEAjUatqrA54w7Ep//av97iX5VLGq4ZlBS94MGq/gJ9frs4p9tCLzgBY8AmV/Rdauzip40968MlHtJOGDxi+d99Zt3ftaEVeymby+PXDG9yzZwe1sOXzEVwPwOcT+nroce0StmFYlIn3NV7UVumP33Le/dBNJ+xk8DgXKJceeU3vpFurU7SDcSI79116of6xQ1vdT35zt9uvVVZMOVYfIC+yu1lu0J1618AMnMJYCCt0Ftyl0xdcYc/aK27belmh6H0AMtGVr+neovd25QsW4cEvrqi2ATQz3jskJj2lRg0ijk3AH/8dbae9e5OON6cxowoulBirq5jImUH711/ORAejcbUlgfAeWcp9664ko7xCaJ0AecTyAr5vQFEQWO001RBkz9qrbl2/viOpIVRy6DQPqQIQVg7Ouqr3F3i5xL8QU4kfIdi1etTtjvn5wQW9DEXGZExOjex2v/b6oHtAPvlREYnyMEw6pj8/fvvJdF+/XL2PvrLZfPkP9M3Ka+eV1nDrj/GThwQQTjuuVn3ZGRpvPpyarypyo4zeHq21uNn0LdPUezalDRJFVTxSDsp2Ukp38GrsfQ/VMa/PIk2cn9Dp0LIQRflI6Z5yUYXolNE6Y0oFyvY+QHC/mLRKDWtckkSgrfjjbxVtbLVtB1DXWfzEVSBuRePJECrzMccDdY8VsiGD+JsG4EPg8Gvj3/YnMaelrAyznoUyyaf8XqlCGkTNA/iKEqbg5yeUvMytiMPy3yd//Cb18OaTN+nVvnyUU7x2sTWCCKUKY5jk3O09Pt9qpSvxJd40hquUSzcKUH1R1mCd47F+PUVx4sM0Y07RAIpKUNj8wMokKU+QxRlM28MwFpnSvKejM+9GVHeVBmIK9AVQBtO5JspKKb7xILryMAkVGUYJk1FWIdOY13gJ83NYXSMrPT+2dkhJCGJJGUwaXzPxqlT77/nPEKGeBoZWj9cX5lsqSB9Xq43h8m3q8ZOaPsyXoz5ewsgZTmEdKJDJeftmfYyecl5CQz1pC59PYcIzDwI58Yi0dFG80BnVgV+VSh1H0tw9cjMV8cVkSrSgD9RBo8eVAYHNWE2srm8kf6mrBsoScNSVPpGIcusGFURy6OQaBk9YTzoxu5pqk05pLB3UKZIMWRDHG6WrFBZwRBDFG79iqEN5BDHY8ErBlR5JPYSh0B9IgS40w3ApDOupPJYkKmaxLkaC/SmXyKPVpxzU8J22t0TVWYpaNUBusBIID5ZCbeMbok66TRAaKC+ZlF2gjYAdCaXxLvRibU2OdOVewXaFJiwy7kF6OdJmSReNHaJJH/z8hKeBx+X3vQe8c1aGz0s+eloTcj0ExTBfGMRGZZBXyVS2wqBV+WiLxQbKZSt6AOg3kqAJGkNEg9dyDwAGOLxMgZEhwyP2qvBFkEarjKIzp2kGYM0khTcACBb8nBGto3LvjUt0eiWAeFnYznxWYrRb97gV5YDT2FfJEbwaQHdOqknl4yrV0jXkCyGeT9rga3SjZAA0zYoGxvzQcVA0DOnHxjR4g9Je1g+aLa+uKKYHhnTeU+dH6VHwIl1saJwYA0MaPRQ8TJ9p1SaOuixrEM9tQWaXpObbJ1a7c6MH1ESE1ge4UK/I63HP1svu3XKhMjYXv+rCgMB0ypNz6MKQ3MLbNGHy4/p6ykcs8VoM6EXvX3voiE3EaD8oR6Sw4Jxq/Aff320uUuvV6qFKmRFoFrRO6SuSfebG9LzAooOnoOvvP71Luzq3VSzMmaooDn/7+/afdX/vTrkdRWNQIQws4+InTw65L8nbw3fV7O09j97SvXCpz21XW9i26ii8nZfQBo8f3eT+8tUNbkAOktKwB16opzopz+EWaUAzmwP9kK+dNWgBbgQGfzE+769f4PQeQmoDjFqrQfeT2k77K9rx+kM3ka9+5bHUKJCO7PiF19a4G60X4eDdIMbpNFBun/I9p4Wmj26/6v7BW15xvdoFWfpuAYi1GHV2eMD9or5e+OTVbu1lD1upq9eNknkxh+8qb9MuVBow5DB6IUn0ff7EoB0/yUoq4fzY3nBZawAFuW5/7I7jbtfGi5J4zQSEy0BXLP9fvrLJ/cKLa909/bN6C4s+BvDYt6pMTnCLclhMu/9gsk7rs6+/9PIad4c8UEzeQ/nwYqPamC9ehrBG6Fn2PUCoDFZ7QAO22zg4q06AIfidsWr9avRGwRpeeelFHtZR7kNSACws3bEXinSMlItgrhe9/RKYCQlZpwawbHvAejMP6NbHJzixerMU462z+liIGjH0EOlYfSi4KZsrWzC4psF24d2liHh6aMJyF6V8th16qkuLYtF2aNEEbQyPoOUtEv7dPTNuC67OWAEof4OjwVju5m6pA73RXVp7uCE6Ph1MoW5Y/mbXqlaMAtAIMH5cDVAvBAbxJlPJtVpvZqUjP8AV1x8vxjOXgOHVqCA9CzBXJTz+/QEmauUfOOm6USYEjoUo/a+pWOSrF8KbXCE9NKHIFo5Q655foIuxNJNJxvyMrS/JXmxWOg4WrlbXgL+dV8qHpvOiZat+GLRWQWxe3SqUyw+PeUGaICve8Fn3aWhD2nBNSxMPC+nCNR7Xqntwh5/hrCFE7aSl2ToF+ltJmx3ObLNpqBJT4EvgTdxPnCS6lCcZsUKfqU8SfJCGDA30OkkciF2cpyF+OfMPAWO4hOFIes5q0U1evEX1AmWsitIbn8Us5lBBCrn3z+qBdWc9VsTTesuoRnNBh25pa6gqylWUUwAtRiVYuoaobOGol4Tlny7p5zeh5U80TOC2UbA8yo8QmZsxGmZYE1tYM1gbpaLx9FDFPIW2x+UcF+haFFt8rUQxkiiDPUXIvK2HRBMhPSKG+uOHatDAOD/IYwNFeDyxMuO3hSl9Q35Kx2JO6VhGPy70Bc9owP2q3GXbNAPHTwwEorgOiiLpTFXk5FkJgILjV0+CuZ1hvOKaGSsav8Q7cMsJ5fFICUy4dGX877maLHkpnzVvUau+pHbfot8orR6TNto9ax2A+rLnkk8dwa9YtvQKwVulmhLOGTWCrYdE7WC8I5eQIH7Mu47pYSfpCa6JvCyvfcrfndFrFP6fX9fOz0GdeaPZGittaNrkqHP3/K2T7pkf1jEUzDigJgJucTj9ycGt7i9OrIo+mBZiV9YVa9Kp058P68uSjzy7XQrN5LDccDCZQ6gu6LDfVYqA56YUdVSTCfsqeS6OyMX5m4/fqPcYfF7DD14pwKg2yo1oOzWT03rx1lF0U0loV+rLOxc/euCke7e2nlP3uKDxrYc/fXGL+9zR1W6zNBqLHEQDgWfi/NHbzrq7t12KtlLXRwqHZb14fsD9i6/fbjtk4XMA8PLp1RvXj7in3/uieiRC6gTqI/fo906scZ9+bpPbIK8c+hWvU+G3/5ARFiIt/67uGPcf0++JH7nibtdRFKZuoZZQZvdz7ltHNrgLqvA2neferAtK2JYUrDpq5KuTXe7nX1stPz8HsGqRyRrWNwN+Zr5ms17uTEJ8aG2yScc4+hKLXUdW20vgNB3cRpXEOvuWwmbtSGx2kl6bisZT0Lz71mlruPgwD7Qd+m90Bs85SdE2JYx7Y6jDsPi2d92oO7D9jCK1xzMNRxKp8rjOSXd8eL/7py+tcXf2ej9/MAjrNMz465EO99kfGHN3bD+trqBOvJQDbn2B8rK2jp8XzZsJSpRfuGuXFkjks6NA5gN57eFd/azKUUc3p7ey/IlxPhcWkzkCotCuk+MS9LX1UewxjmDp3iE//6DqRv2w3sTBLK4Ia9KtqKCaQH4Uar8Wb+L4Al6sEb785Qb+i5oJqtT2OZ2kNiNrjJFMA4ZGU3rDrGjrC7U/kwoOjimUDTX5S/Pzs3g3bCZb7aLj9NkuzVC9HkBeu/Rj+3cmzeNSKr2tZgR0SLnyq3QCmLBjpTi3E82m2wZY//PWSg2qsPrI8HmX499AP1d88Wx1YDJcy8/fSF3AzZErKwnMEZKweW9MAAAl1klEQVQkWELHEKhau1NX4jmKEBypeBJ4MafhXNakn9/wScpek9IhkaRjncIPRhOIUh7JjwxXo1knCikVP/rn6Leymkt0twhgFHDt1x/RaByay1V/OYHv8Sv3iGeAEBees6710upXgutNnVXaMg8vT3o8+/zUDUsClCdy1qXVy+FYnXFxkq2CjXpAoRhaMtTJAhrXLBSZo7INl54ZejULZsuECLQGuulQQZRn85BI26Mio0TZF8+lelOXqpKNsM0xxsM6ylgxWyHqqEtmktBsNvXURNcUQoGmAprY0Q37NIgLv5AjE6VFkIr5whltT+LrYwgduQGL03VAN2viJsxi/R/SnpGU8xZWyEs+FIbXBNerdQhvBnBQ8FEKL/AeAycyXFU4H7Ojzo66ix/1jKk9z1DJUMMMqmx8Dl5exqcm1AhQPjvMIDz70Nb8Fe7EvMBTqcGS6ghHs0q9phWASrN5a7c8OM+c73P/8ckbxYjyCBImcVLDWW0r7pdF5BkffT3AXIiTHfYPTbpP3HLKTklg4TAIrMc9505oF+N/eH6TbXlmsm3OBuXlWJJNOiH7YwdO6btmM/YeLiUjMkycOcbjDw5ucce01bc32ihXiy5oYu8Rr5194vbT+nbZuE1KI2Nv2UnD+gOnO/CCO+P00BfWwo+iPKUTIXawHVp1hd4AGAJ2ZT762gb3slyafpu1j6WMUTlUHt5zwd255YIm0ihdyNn8lUluQQcEvHhutfuyyuXdcRQtXh94fkSnaG+VCzTutQqlXtMKQCWZ0PapYV6+3OO+fL7XBAzeI6BcEdr1it/UoJsTXo9pcrtWX0V8m45zr9jurDgrQLsuD6tx/t+DG63XQcVs+KG/7Awd0M7WB3afcWt1KoSTUEAQjcrx5SP6CN6fq1EndEw9BwUg17WA1xo5XIpDDTjCfJdOU+bl9pJ1FG6nieS4tmn/2Zfucp8+usrdIe8XJyjXBzm3S3xiO3RwU4Z88JMe5otaGzqp43Q4bZAwfmtVtae1Jf1zqyfcXVtxscT7JT0uAJjknr7S6z72zEZ3q7pNna9hbQ5Ka1/93Sr+cZI2tCThmlcAmEDFsaK3iQk8JwHr1cxaBtaUHiNsdzarp4YHvAtO24613dggUTDWlDR8KnZWPnP/wUBcsHLdzXEwWKfhLvdXHk31v+VCcGUWhZdrGOKYxZQCcBhWv3jxQL+2O2t7MSvV5ZzVSwgHKaelouYbpCBb8GtGwF2PFADBZEtzO6BTbftmbZXeqZ7JBmnl4q04jByGMA2ueQUIlcZiTYgRaZAempayMizw1Fx+soqcJh1cf8R5F1xIVZnXRE4FW15ZMZSJYQE9i88XlBXqsnAkcZafEXrvtkzSRDgWXMcfahi2RjLZyFoE1FQDBG2+MdGhWCoLBWwH0LbDkvxN8kZQflLNqpW64hSgmihUqyiMrxZfDW9ao5G+Ik/FQ1qOamFJyvxzKCNckxiSuZLx1WuMovkUtfHMx1wtJI4P2nlOE7QFsSxJQCiUawOI0+gygpn1h18oC7z2CzchYpGuNBhjSw+hpqHmjP2ae1sJDJwO7Q8HjleGsgJ+wqNnXZhc9SsPLlDl9D+VH6jD2oVfHGMj90yG+1QOr4Pynm8cODAMSxvKi8ctx3uoh1bjCTyNCI/zqLKG9deCfGypZg7CB/n8GbeBM+oV1CUwzPVzISVCsAFdKhVAcfqviZQETTE5zZ80rLKu2dKL4XTZdDFsmwAp6RcDKGdEXpfXNH5NlskzOwRv0Eyf4/ei6tVFFnkZArwgL0XSlVkNAcL/ql62PyCaOjumXYcmvDm5FMMQiG45pzBeqm8cqEHOndNk9ev6RNNelcF7sABDJOjEvbpH422vgMQsb9A0306ly2tvDm/WBQ1AAXIKY0McwxeLarAqbMt5ajzvxjQMGlfe4O0BF7zapcnxOsmzTdwVaF9CYslfv7ICKKKotpoZ8d+G+soX5tzhQ9IehZVdVt6JWCxq957EbJv2DbFVuN1AIw9LCB7ePOJ+dscl+yCdMZAaCmAiB8Y+c2bQ/dmx1W5QFrMessDLMeC3r5lwH7vhvG1eY2xsk0Yvg76AtL80lvJPiOl/enCX8lZaY4yMuVjHuuR40Rcdxa8wqk9DF8LC+Lxb9fnJ2067H53oNDxmtFQedaX3GZPCfu6VDe6Uzr3k6D9rXFP9iCkB4RJfoYae6k5Z0sePr5Y79EbbTxRkyvikuj4n9+puGTCUANbXBRhjrS1wvup/efC4nRxeyhvh0RGg7oXnnfujz+sImAHvtJgTszr0AszsVX33LV6Q5NpUqG+tc7/3mzq1V6SwiSgIE9YHe6Ztcu6+jxTdwAE9S8VCZRTVcqBCDAWOyfLfumHEvf/AYSkAZJeqakKR10fYOjt2u98+vFq9QKTtNahhOHVO7kdOaf7hW47KS6F8siamADXyIoh5jkw5t8a95/MH3LBOmF6jhrR3aNXqNDyNiQsQFys8orEJrwbEo4R4TN6596QylOtJPuI65Ca9oh2O33h9jTusdQLcvKGNquFeqjhGCkOiERfp78hFiuEJwC182i7hX9VgPcjL0TM7OQhYhzwnAX7nZf0HXp9zn/zzWfdOfeFjVl0ExkgqIFnWR/KSmehji+qvtmzSUeVaMjTLExJRIi7cQ/oJsXXzIa7NVwi1jzTLrz0nN2EcEEbGfyywVMbEU82/R7RIj1Cxy1CG1dyQVLMWkLdL4kwD7NOW5qK6cA6etbN5FEc8eBBMGrgZ8AfFVua0HkpWjzjP/yaRV6Jt+xN8GJKQr9MvDoFPuC9tnB6PrPMens+y3pEAcOvgb/Gfrf5q6R0K0AHUfuyulWrlma8AIJESzOgk8pnkieFIS1QOrt56BAV0rYDANqxzqoW2cC94jZQXGoABDJNgXJl19WjUnzJVGGNOVmDnlDGtEZvlU1o9wRXngacgcKeRmi9+WhR2MqPYZnkEOsub6CmtGGsj4ukh9cDwhckIFon0IihdAUAqJbAZly4lQAH4XZMQmoCrmFMTfHpScofSmBL55qiZe+EJfPn+78KxLRaGJaWXwvkh21zVeJkKoOj5EJOLcBuu8cT1VDItHzhq5U3LlxYWp6e+e7BEXKkvQwtThbIbQelrzdCCu+TPY/JpGsG6lGnTqCUMwx2MEs+1ZMSSp/2JFxDdN6YAEVLycvBTF/OFoE3WBF6AmPXT3WUBrwryTuz8qmT78n2l9Ve4GfNXQBRWzySzIl9EAZRovdTmOxVznljitOFIiK5S1ZAk5apc9t/Xx4YydSCi7uHHZLJfE5ewTsBzhyoww2TGcFEn+iUP/j6Ul0LSEgZBO86OSpnwH0fZhYxJ7KHf2n8enaGGlRG0ZfgpZyo0rAAghJ5T8lGflO+1U+Op8HE9SoCUfZroDGhGz8QmWTDP56Zz7pAmrHxBJU466cmb5g3ACuArLshn7L1AZdw2MVQ4X/0DR70ALaRHGbs6yK+6yQvEglugizQwfiYx8a63jKx04ESpeCk/r+9cdWoybe2ckQF6oIW68omkTlmRYblCvxatE7D1eUD48Gp1aJ7WIV7wPmyXGqy8NkHeOe014svqwXWaUeAiBVMvRtWcWfqqPH3JEfYmydHhMbb5qW1UHwxvaB275VHjdQxY6TmkUCZby5KU29xDCeJpyNqQAjAvyElqR4TmJ2495/bfPe6mtRBQnjTSqHPuO3LPfeXUgF4k935dCgJoYI4L/Ds3XJJL86qdT1myrDSsBJyTib9wfJVbw8YmKqA8rPDukmI8I1/xZ5/e7y0BCCOAOXhgnj83YKcEp01EQ9r4lZ4KBh/STtE/fnavcNi8qMQkFGFSe1jYVvzWnWfNfceQI8nEOM567hFirPZlHbr7pwd3ukGdsBC8R/Xk9zwpur+975z7wI1BHHxOH+fkc1/rntQL7HGAT1hatmIfl/t0jXgKb5cSEGgM4nu3XXU/t23YvGpx1y/UQTdbzz/z1E3zea9GKp676uaOapcplSNxDDBqLz5fdHcobFqeUnP1x+Nj99VvhRgFyMu6nBQZD+4+5+45cM7N2XlCQky8NCGXn3HD493uX7++yr1XPqjAYCqCQJ2Syb1v+yX30P5j2gWpj+FJYQAsYl4rqlOz+9ynjwy5h+RaJC/5EOhBCerjZ/vdH50cmMcE0uCJwZeMv9ljBGt1AC8+9Fd1dMlXv7fVVg2xQAq2H6dBPC0L+/P7ht19O8/YYpcd4inruRAgN4tkw5M6tfrZzToYSs+qRC2s1Asrj6V8s94l+OP3Peu2rVbj63thGBLjoQzBmN4l+LlH73S/dnQw2u7s+Wi8FA563h3RtuZ6jYWytAXYgvKk6vPJTSPuh287pMVYCViMv7w0n9epEX/+zD73/m9sdwe0fZtzqqyNETpJ+OT3zrhzj5wSfRxsUwaTCz1qucqt19rWrI77MedOOUljPUDIh5DMiOl82XBaY5NyDyAhl5Tjr+/JaE7Ly3BCH3Cb1lbd0D2Dmzj86liFpDDwzHj39m4fw99Q2XDPcKbRBiUvjXCz8IIv4OKKleYbWAMSljIQ0xrAINwgRY+XWw0zJaM428XzVRgI8X8OPuoacHDWJc98xvReHTGyzbY7ewWI1w1PYOtqUo3q2nF41pGZOQn/jH0kr5yHVumKjOStEv79qs80tTX6FSurP7tavCDLXoUnK6YgFr/Y4ZAUfrI0NAQiQwmEmOmVuf88PdYIWCI9ElNKGr/xjcBf8vof8SEcnP4+nsvfI4aTRGZAeokZiWPBoJxKwStZs1POqilVs2WG4tPKDXFpV44qZP++ubJVuLWB8VKprceE84zv9XFopQN/WhkLpTuNtmbDYD30eHkAS6wxdEt9gCtSEt5HoLe3EOqrUcmshnTs+dH5KX4zEIISB6VJE36SNK8AnqZyMTyrFvRK0W05LnGXzGrRqowHb60SWUqPIVUpoEU3aXgJC7+sYmrVNStfCE8rN8SlXY2eeZkI8IYj8JYQehiu/JYjQCs/5DXQHa7QHO7DNT7S8HUKMVEdJegm0UkFUHAWNK0AJugqP354KmF5iOBaIr+yaF8x/dXYjvEdH+ExkAKwsYkqxStfmbu5J3AyxuarKmlA95l28FWJFqMN+vzPeqlAr67pWNNKam0Y9DDu52o8s2fxNOJja0tbGDZ4ZK7zRBvwttiNmoch3Ea3rDyVCTxFRvgBG9Ql8zomQ6ZSAj1P6kcPAA9K4dzXAY0rgEpBYLq0FwiPUA+lWsmUphvRWhCFV4L0EBwDyys3nuucsMmYPzlACdR4+my37erklIQSyljeZm4hg7nFiLrJb2n7Moex8lwKV7m3qAF2sJ8nUQA0MNTA/dqjzXYdMqmd1kAKNHpnXHendb4NMz5RVF2PJfp0A23d4le+a9L1aC5lE0doglY1wnJxc1Ix6IbneHu+qwk6n48KRnqP5OVFHX2I8eyQTHSwey3eEgi/wqnw95TugtrxotIy3yPZhCbBByY6HP4u70mjtPqhfgUQAUWVOqeTpLcK/xPfnnPDwxp7VewGxRJpq/TVortbmsGXD+PA4thm1ed7J3VW5uwNdoBqmAQzckXQnj874PZH7jkaeaGA5WfL813a8vyRbZdNcCjLrLj+4j49KS/Qn2sbNcygzMBCvFAcqPq64h99SVueRbu3tgw3fN5TimOibF4Yy71QirPzQxtTZrayM9H95uEtbv2ZddEJDJ4mBB8352ltk8YjFrxw2VjbH0Mb4Od/t1ydP71+1Bwdod/E8tsEWMeXPHpwbyYxo8r/n956qmJkQTsV1CgvT192fyq+DMqRgVey1ICZ2MoRufv63l3syfeLsRwDC4trgFQ3p12iZ3TgwItKir6izeSEIDk+3f1/92Y39OYtcnPOSDAqcfI0rAY6SSeghyBsCpZw4cqUq09dWjycuGYAHLxR9eRYwX1K6xYfuf8FWaLy4IzhQ0FW9PlTG9xPPHqTW6041iKwJAG4YxJ5TA2APkv2jDbC6R3WKGCTlGQp4JRouizmBxcqNDFhZ2csLuEkf5eCRjjDsOXrYx3uMw8dc++55ZDeMdE+2mgoZG0gN+fnn9vn3veNnXJzaku5MoUeYp34+93RvPvMgyfcj971st/1SUUF9BoFCeA3vlR0P/xB5956g9rkgvImDK9PXf6LdLHkNj6Xth26nC79TgSF7dLbNQSigiVgIeKwlEHhQSlKcdEN6dfIMnHoUxrQgKHyafHNhDEZtLGyHawajZnphtW9FqR15SO3oS7iblQQIbzBdJO2v1bG+ATQWs1LFKFpy4XzeXamYIZmaOK6XIAhEO9aFOf8dnbfYyqQIQ5H8+v25p6itpbzqmeZapQHRcfRS95ZvQtiNlXSb8lkTOc0EeUwGCCWtYykyl2GGFbJQRQ0ayg0J/8qBZpg8EcNwjMGkQpnAUKD9qZBRnBa0obDPHUiVMLvy+FvrETP2Xl4SZEl5LHc8/K1OyCLJspdSrqq1ztJGW3h2wPLT6/KLwD3bOH3NfIRlhp50yMf91tIbZtTgIieIMRGViCIuDrAV6WOhC1MEh+NReR67DzUgKWgtwZJy1jIa1FeGR/Yb4YxiorzO1XRowQm/5XoGnpqXgFqFYN2GJHxqvggxqZMKNOA/TmpFU5LnAhjBFY+NcJHclzeWnWjMJkhj3WlUT6GRd7NFs1+oDm0RgJ3s4+g64rKT+KgwdPcryEdu23LM5YQ6q9wlbyV3K1MU+2J1W+GhmlQ7fCrtPTxMOYjflenD4U+2mBzNCQwnsNkRRjtagM/APLtxHedsfoWp7zwYId+gIlUiLAAn46gjKqQqiq0WAEiMuSmyMk9xdEdfsBWpgEhvSDP0QkNn2ySFlWInIzidmj8xL4fhKMRIP9VjRVf176SiApjIscePqNj+Tg5oFu7CfMsCUZl0hg5uTG7tCPTl0dO7gKGRiiYnxYsjGcPyU3HCjYyQNGE4w5eJVL48npaaaQ7Mpn3k1zd8wyQFj7p9VbbzwM/Qxzx9cIxuYQvqao2gRYC8FJznmkDtoE0ihcc5+XqPCkPFb568vPjvegXNZGlEN7dZk4VVNfaQO1C3qc1UcZrxQkYOEQIXK9sr7IbVAtMeEi7Y2NrEy+FcYIJL3rRw/Mja73QWgWQ6Wa6Unz9irb6CPWMmio27uB2VG6qh7U1b/eNiRMnRDVfCXzxQq/7/sU+8954oaxdFSzZmCZDd6wddx9cNybFgxM+H4z+X7S/aKh3wv3Vka1SgChC0TCQ0yQOXeo3gfJj0XJ87ZKzU4CF3myDzg59/56rJlDmp1YE5XKyw1UJ4TdPDupr7fjtfcORjx6Qr7V/eM8lt0pffGfyGOoT8pLnW8p7WS/jY3GVpSaAG57iev7A7mGdayqfnXAbS4SAiSk0fvfMgDvSwKG8FAxuvGXv3DLidq2aLOO1OE1sVc6oDN/jh3ZIuMv+Rl+fOa3TOPerd5yzb6nF60L7fVg99/T5q+6vvgL9canQK43S2IPPOLdf5cxoXprc7angqtA6BYBq1oRk1mY/f0pW6kRFwTCIwr6v3y/+QYd7xwN5N8n6Bm2rH4woyBL/ibYlf+ZMv7sPdxiNU4Fl/gPFMuw5or3xP7n1svvQm16RwKgk8CrONuZ1TZnwP/CVve42aQsTJ7MwxOs3pIQcYQ6uEK7bBQECfVE90pt14sRP3POKbXlGCBA+BKBLi4EnrvS77527VR/K69aQ0NOEME9KYQd04sQH7zyqEw/8tvEwXAl5L+lUiFeHb9M7GZ1ubWLbeRbhrBGw2XBWZX/g9tfdvvWXdE6o/5QR/Ic2To4e/86t7q8udbubtaFuPCasWXgJp75nVN/37Dvr3r73uPDqOBjhg6cYJHrfR5660b31Czvc3XwHTOXQPkPi++PqoR+5/6T72EPPaYMkfUdZJsjfraD/+pmie+CjWjVWi2lfW0kN6Em36cduT95hz9rzoySp0DoFAD01QqJW64aN2FAPEK6uzHEuyyEC6Me8cBPs0/GsDGJWXMeJrgd8UfQ/4KZsH8Kon29AMTC6W7XlpGDwR9GGmudmyrTMVf4YBfoTOfHkfPIzEFs4Uz6es4C8Ph20a5tvRLCFRTh9XislC00inIZQ3Y33lA1eTxPhxPoUpGkcjGbDUMYLPuuRqYUe9kuYWetB0TB8fANso4ZcxOXUTlrm00+YIgLIz32HlHG9bvZqb/OUtjWHeKLZ7TmbsduT+GrQWgWgJChGCZIShVxKXblY3RD0mBQShvXlmi0WiswAig044lY83FMUmx0YcXNNvsVmmTNwNxtsjUd5lG3le0zQ6enh2afyMbG/lr6c11LpTwmX4sHjzQh39YDPQUpjvR5L/DFMvhcqp6oHZzkNNBolMbzEEoYScPWi4fnPM22haYPnB2kU6F0WxMbyKo63uuxcH51YUhrqkFdIG7X8hlx/Wq8AYIZ2Tz9PHiLuoBeeFb6aNv4khdITXmKiz1X3X4ojrx9SlQsPZRHJBMsLog+tG/mCEpbrafRFuIxOuy/TWlGMEhs/7OrrRXyoX+BbRu4KVKkPGp4AHh93ojOUyeNCADzRz9CoKOYXCrJ5AsM45jk8I/DsG+Pe0nATF54oL2GSe1vlnWWonTSwZGsCmjG2TRRTzmL1Kz+m3HlGpUQ0EJRSSsTkBpC0NqnKD2C3secQnnpNTZdSv9TMVQKTePWcDKqSu/GoCHka5YSFsn0P4NFbLxWLC4Wm4QhxjV7b0wNUocIqS231s8pGNQ/3VukozhLEcQWzFw+L7gNerIsfc/oIu4/G2v4EBeyqn5wFNHg+4svvIbwVV9S59IM2IYUmhmKezvnNaSHGgyiv0gcgT/gR5jGG2PqvRlPApWyeLq7VMSb9/KFEhraDMqdVc6txPeepnDJE1Yo6I9XLB1scNJEmusaS+8AW/V1cBVCFNV9xnUz0tV9IO5D9+wNUhhqKi4VOubw0gc6JsuhNOGI9wJEwaA1h0RUBLmiC2ylvg08DQm7VKvI942J9XP74G1UG41DrgkUPiy58jXyjJlk+h2VrwR81tRDieenShjtOj2YNgm/oFvFu6Zlwuv0kEIKuc7K0P02ZLxj7dCg4p0J0iT94hhDYSGySaKo8cwqGNj/ikxeG4K0x+yL+mrdIeMEcB54vaMB+Sn7+sH5AIurZp+sLiuMrOZmg9aE8basZbxizc53WqmhBi0Lm56dxYgDucLJD4EssesG3i6YAVGRWbs+bRPLz8tt2a+vqlBzH9iK9wrAMbPN95dBVt+Pls25K735y3KA1Ai3Dhqk1vS63qb+ivYnHgm+TJ+HIcK97/Mg2E7DQepSLi/GUPoT3q7deqNghGeLOauvwY6cGbYIOPhi9UMDCs5Hr4mTB/fXRTa6XUy4QfAk8Fpxt2Od1cvSkhAmRsYbWlXx4RHBXPnVivTsxPGhCFRQl5B3RGsIV/Vhlrnc4DG5q16Hynzq5xp0d6dG2agmk0eQVitO+T4tX62RMMA7kALiymPeOFD9/KV55Nw2OewUnMA6S9LkLI278mXNudkhty8RVSCf1u1ULfq/kr7on+KQZb1hVgHz9YshLOtnhZoXPSIbgVaug8e3QCylZdWMr9bAq+rrwaBGvQtio+k6FDKhJuQ/Mxy8k77grvO8GV3jXnlQOkJYXac7CWN0D8InvBTw+WnD/5rbz7qe0HRorHBiI9eSlkme1HfoffPlGN6RnegoUqhUAFnqas6oMi0Qm6AqzcF37dbNevU8W8KnT0Vg+0pEX3rDleYPygrMZuCjcem3DlD7k16M9bxTe5FZqLP5hWfh//wOH3MMxPz95yQdAG27scgsQ4JuLF6ge+d0Z96GfmXU/qDA8OqQkL3UY0d+jComzw/ApDl//Tv0G5eufY+2o2UoLB4CxxbXc3HZoj6O5vyKcrdRrNqrh+4ySeXhmp+QhkGWz7phYOERrn1RnRStkAMl4O21Pok/rFUfxPdOg+OP5F5SL4QRNTmcfGjHZeBnF1RVsjasitsdbNZaTeMlhJiCIUJgGtfKm5YmHoTxqhlSApjI/KpPAK+NZYv0gpMrKZ/H2vqzubtCPLZ6SB7Axqh2UgtyJRcwA232ccqxJRvK6gxPiUne+5hOiBFL/WdQ6hVs2FEBCA5CGMUGdoFFGBYCKT2GDBoH3DPcibz2BImgAy2ZaR8rWQpKmCuxVikM/q0TXiKwoZd5DVdwZhXreCZXiM6ZiZcM1r8RYABrGm1uSBQC8+PIZImcB8SF9VppmwhdfAUQllbEK1UMxEhwkNaNhAhqiw/CGMJ5pqPB1SMa6iL6/kgJgHuLT+ufW/80SllolNZuvFl7iG8Ed2G49J9KqHxPwUi9dT4HxNCBEoGPAwlYoJxbc9tslUYCGagXDSyAWwaWSlBNZZhsb3eKdBTFsu+aTSRVoInzlnFFAGy6UC00Msrz6eYrDMxPN5QbQy6wrTi97lNiBCuuZiJs3KpXwygpZeqUzAa+MSs292IHLXwHiTGMMaS8SIFYxUBqsEd/rGqZrjYCsQxL+l3QEIWd8LjZQIgJ+Xhv1MHg8QxNXrCnbglfL/crzcgK+xzYqLxRTF+gFmIZ9X/MzPHU5OQ66GU5KKeYBbZToGlCCnMb3fK9rucEyJCnBIqRD0sMEtnhpQoegavZU6gF8Wvg9qeXx3Vtz7h27ytE0D/ryFp1kvXvNmHAsnqhREsI/pINv36qP+3XirkQQFA5dDCHGtaX52Qt9OiEDYVLgMgBou3f9mFvXO+3dthFN0PcuTWYuaS3lhZMb7FSKNJqLw9qTPKZJHhUEmYALu+OPH9VmNt3byQ3LpL4rQwHwIQ52uLlvnXdzXz8PT0sAc3uHnPsbbYX98P+Vdz/2AxwMVYou3fhhiPf2LAbvKe+SBPyuVWPuYw+86AakCJzl6X3u2g6thbATV/rcp756izuj9QDehEqju1SBNt/ITpigXpVx+eBtJ9zd28+6iWm2NNNXASjprPu97+1zf/uvdriHtaV5QlHwMrAbAzPxuUNu+psnFMpqZ4jxd2omt32NDIM29SzUlSlULYHlrwChmibpeohTDPfxJm2QNb2sVWAJUa/ik4JEMpox0XEopL1Amayq8hlT6JrRvX8fgOGAD48LSXupqQ87NHeL3i7RxxZsDLkHPYt+nMZ7tW15UO3RZcOgiK9Kp2jXN8jxMbrZrVxsWiM/bacrZ0rhAbQwXZYDxMVpOdBTmwYby8PRCNhLG1kiRtO84cSrmBHPQyq7pnXZFQla/EDbM1lkYY1VYGhjiGwTSN37BTdSLR+AGqML+vTzpy5An2IibeBtNvukZkS256vC4gxmzwtuzVj11IH4dbIo33K4rCwFQKqTZhxz7/8br83CVvJ9SfnMoAsZwHripeKe4Qay5GWDSi0vwAMEcdBclmnq4WllREozwHpfB+jnDqX2Hk6EvdQDEA2UE/vnZfCXtnjDgrVHGxtFsiCICtCDfy5flxXjK/hQ8dAQmeQs5Q4P4doQpsVJvLJ6gCo8gcfBKnHlV7Ze8zMijJZOwyd7u4gHE1EyGzY9x67cpgDBlX5+7z/Hb85p1PRIyxKMLP6EikX11sXe1OMR3gQTybPuGV5alfTsNZqbGCiekIA1FrMsb68NBRC3YTp+5k5ts/YNU5vfyDzbrrtwcnfi9fbbleflBzlbUxNAIwc/P3NxZIWkAOfuPKs9TW+SJ8hguUkE/uEkTSIe8e1igYLt6rIgbA4sVUDBBR3UM6st63b8n+YIFTgwHCwUALo1ZnBdxrDyFUD8npVnAf/yydcldE+qCUOb1WA86fBPv3peXx88MmxfeqcNK7xIesj1drocu/dijcntPD+/wkISxOBdmrDvWT1uR6CYspXUowZh7YyGQA3Ui2euuuKU1DbqJgPLOkXoK8+KH2e0tjKjMzdLPZhSKO+pF0fdaq3FzGi7OnUK+TzJmiUMTyqZao9FCMxoZ30WiHtxt0MvkNjM7HiBZLGmL+n90sxE6RHYdTam6i2DRGOSnhbUGfwPbHSdP6I3GdiNSgZdGOKc11n3D+njbp9820E79oSXQZg4xhEx2cVgxgEvULfWAY5f7nMf//LNWgfoNldpheLFM7TqHonFQo/PuKlHXnDFZ7QvPeGvp8byVjoOXkiQrRAt7OmH1awUfGIiwP2vLe/ZCULCpbvSyy3Nduh21VktVdQWiIIWWdYjyQ2Cbc7DPx0HWrhXeE/qhkadB94ngpCw5dr8/LKsafOOtgv2PNpqBFA3vZDEJbdFf2LuSsL6ZEz6M6ScVdxi8O8r7TwgDiQrBFb+ECgwWqYrR7fL0QHNQHyIjxmkEdmiUKMfJxlDIaYInDqRx8omIE0pEkkW99HqF9WNdRUqEOrMFRdmBlgHRxVD+ni6tLB4/DK8v3YUQMy1MSlK0AzQeAFoYH4y3VxKFs0k2UIILQHDHPsphOv8FKWkdhMvyktSZXz7nuIlUzf1WHRP0bDOytXj/LF9jKKAIq2SaWGxrMvx1itAYty6HAmtm6a0gWs9mZONR0OHxia/SUUkHQFfFMZrrPQAuA8NTRquKAwdIh157PDgON5kvlBOq67g18/KDTiT9SQ8LSykbzeNoZx2X6O2Lfgvn2vypobgBXXaYzkBArNkNGlIY3yCiA6dzGAOfzFIzzbZ1aSXUw665TYs6NcRJsE1GMh++hz7beRS5BRtjxuNMNQ1cmdFRy3qVdBwVSgw2Whb6qAi8dRY7USL9QBZaBcQvqRtl0E3NHk+U2+1W1EnBBc72PqqqxiUD37cDASLGiyC5tRF8/X51NllO4lBWOwdZI2pdBTB7BVtNzUvELs29RNNuZkON9o16o4en9LX5LXbswEF6NSxJKf11cOp4Sv60k6Xm2E36ALqU7SZtoxYeO82DZc1sLrIiRm194TkQHVjDKBPE81TlrT8jYQtZdtVoXOO00VQgnxBbyVOu/8faYM7Ismi0EoAAAAASUVORK5CYII="
    }
   },
   "cell_type": "markdown",
   "id": "286495c6",
   "metadata": {},
   "source": [
    "# Calibration\n",
    "\n",
    "Modern integrated circuits, or chips, are manufactured using a complex process where the chips are essentially printed onto a silicon wafer (see this **[video](https://www.youtube.com/watch?v=g8Qav3vIv9s)** for an overview of the process). Each wafer contains many chips (e.g. a wafer with 300mm diameter fits several hundred laptop grade microprocessors). The chips on a finished wafer are tested to identify which are good and which are faulty. The yield of a wafer is determined by the fraction of good chips. To maximize the yield, semiconductor manufacturers are interested in identifying and correcting the causes of the faulty chips (e.g. wrong settings in one of processing steps). Some causes can be identified by visual inspection of patterns in a wafer maps, showing which chips are good and which are faulty.\n",
    "\n",
    "![wafer.png](attachment:wafer.png)\n",
    "\n",
    "In this assignment you will work with wafer map data from a semiconductor manufacturing process. Your task will be to develop a calibrated classifier for identifying patterns of faulty chips on a finished wafer. Identifying such patterns can help with optimizing the manufacturing process parameters for the following wafers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bab6894",
   "metadata": {},
   "source": [
    "#### Deliverable\n",
    "\n",
    "Throughout this notebook you will find cells starting with `#TODO` and `# // BEGIN_TODO`.\n",
    "\n",
    "- Fill in all these TODO cells. The `#TODO` cells are meant to guide you (you are strongly encouraged to fill these in!), while the `#BEGIN_TODO` _answer cells_ will be graded.\n",
    "- Answer cells start and end with tags, `# // BEGIN_TODO [Q0]` and `# // END_TODO [Q0]`, for example. Do not edit these tags in any way, or else your answers may not be processed by the grading system.\n",
    "- Be careful when importing additional libraries. The code for of your answers will be evaluated automatically and we cannot guarantee that any additional libraries will be available in that environment. Please check the Momotor output on Canvas after submitting the assignment, you should be able to see if all your code executed without errors. If in doubt, please ask your instructor.\n",
    "- You can add arbitrary many code and text cells between the `# // BEGIN_TODO` and `# // END_TODO` tags to make your code nicely readable.\n",
    "\n",
    "You are encouraged to play with the data and extend this notebook in order to obtain your answers. You may insert cells at any point in the notebook, but remember:\n",
    "<br/><br/>\n",
    "<div style=\"padding: 15px; border: 1px solid transparent; border-color: transparent; margin-bottom: 20px; border-radius: 4px; color: #a94442; background-color: #f2dede; border-color: #ebccd1;\n",
    "\">\n",
    "Only the code in your answer cells (i.e. between `# // BEGIN_TODO` and `# // END_TODO`) will be extracted and evaluated.\n",
    "</div>\n",
    "\n",
    "At the end, deliver the filled in **and executed** `.ipynb` file by submitting it to the corresponding assignment on Canvas. You may submit as many times as you like before the deadline. The last submission counts.\n",
    "\n",
    "> **IMPORTANT:** Before delivering your notebook, make sure that the cells in your notebook can be executed in sequence without errors, by executing \"Restart & Run All\" from the \"Kernel\" menu.\n",
    "\n",
    "Let's get started by filling in your details in the following answer cell. Assign your group number, your names and student ids to variables `group_number`, `name_student1`, `id_student1`, `name_student2`, `id_student2`, e.g.:\n",
    "\n",
    "```\n",
    "# // BEGIN_TODO [AUTHOR]\n",
    "group_number = \"7\"\n",
    "name_student1 = \"John Smith\"\n",
    "id_student1 = \"1234567\"\n",
    "name_student2 = \"Jane Miller\"\n",
    "id_student2 = \"7654321\"\n",
    "# // END_TODO [AUTHOR]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfd5121d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#// BEGIN_TODO [AUTHOR]\n",
    "group_number = \"24\"\n",
    "name_student1 = \"Ambarish Moharil\"\n",
    "id_student1 = \"1704818\"\n",
    "name_student2 = \"Saptarshi Chakravarti \"\n",
    "#// END_TODO [AUTHOR]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5849978",
   "metadata": {},
   "source": [
    "## Import libraries\n",
    "\n",
    "Later, the code in your answer cells will be evaluated in an environment with several typical data science libraries installed, including pandas, numpy, matplotlib, sklearn. You are free to use them. If you would like to use other libraries, please contact the instructor to see if it can be accommodated. Please import any additional libraries inside your answer cells (otherwise your code may crash during evaluation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3514b63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b7c08a",
   "metadata": {},
   "source": [
    "## Load the data\n",
    "\n",
    "The data resides in the `./data/wafer_calibration.pkl` pickle file. It is based on the WM-811K dataset containing annotated wafer maps collected from real-world fabrication (see `./data/readme.txt`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "621ad3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/ambarish/Documents/2IMN30 ML IND/calibration/2IMN30-ML-for-Industry/data/wafer.pkl', 'rb') as f:\n",
    "    X_train, X_test, y_train, y_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add901ea",
   "metadata": {},
   "source": [
    "`X` contains wafer maps and `y` contains the labels. The maps are 26x26 pixels, a pixel of value 0 represents the background, a pixel of value 1 indicates a good chip, and a pixel of value 2 indicates a bad chip. An example of a wafer map is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20f2abd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[0]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a172029",
   "metadata": {},
   "source": [
    "The wafer maps were labeled by human experts according to bad chip patterns, where each label is an integer:\n",
    "\n",
    "- 0: No pattern\n",
    "- 1: Center\n",
    "- 2: Donut\n",
    "- 3: Edge-local\n",
    "- 4: Edge-ring\n",
    "- 5: Local\n",
    "- 6: Near-full\n",
    "- 7: Random\n",
    "- 8: Scratch\n",
    "\n",
    "An example of the wafer map for each pattern is shown below. Note that not all patterns may be present in this particular data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "837764b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "unique_classes, class_indexes = np.unique(y_train,return_index=True)\n",
    "class_names = [\"No pattern\", \"Center\", \"Donut\", \"Edge-local\", \"Edge-ring\", \"Local\", \"Near-full\", \"Random\", \"Scratch\"]\n",
    "fig, axes = plt.subplots(1,len(unique_classes), figsize = (12,5))\n",
    "for num_index, index in enumerate(class_indexes):\n",
    "    axes[num_index].imshow(X_train[index])\n",
    "    axes[num_index].set_title(class_names[unique_classes[num_index]])\n",
    "    axes[num_index].set_xticks([])\n",
    "    axes[num_index].set_yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356882ba",
   "metadata": {},
   "source": [
    "## Train a classifier\n",
    "\n",
    "In this part you will implement a classifier, which will be used later for evaluating your calibration method.\n",
    "\n",
    "First, start by exploring the data. Remember, you can add as many code and markdown cells as you like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa97794b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the train data is (4310, 26, 26)\n",
      "The shape of the test data is (1990, 26, 26)\n",
      "The shape of a wafer image in  dataset is (26, 26)\n",
      "\n",
      "\n",
      "The shape of the train labels is (4310,)\n",
      "The shape of the test labels is (1990,)\n",
      "Unique labels present in the train data are Counter({0: 3879, 5: 159, 3: 148, 1: 44, 7: 42, 6: 38})\n",
      "Unique labels present in the test data are Counter({0: 1792, 3: 76, 5: 69, 1: 23, 6: 15, 7: 15})\n"
     ]
    }
   ],
   "source": [
    "# TODO: Explore the data\n",
    "#exploring the train and the test data \n",
    "#Exploring the independent variables or the features of the input data.\n",
    "from collections import Counter\n",
    "\n",
    "print(f'The shape of the train data is {X_train.shape}') #3D array\n",
    "print(f'The shape of the test data is {X_test.shape}') #3D array\n",
    "print(f'The shape of a wafer image in  dataset is {X_train[0].shape}')\n",
    "\n",
    "#we would also need to create a validation test for evaluating whether the training objective of the classifier\n",
    "#is achieved\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "#Explore the dependant variable \n",
    "print(f'The shape of the train labels is {y_train.shape}')\n",
    "print(f'The shape of the test labels is {y_test.shape}')\n",
    "\n",
    "\n",
    "print(f'Unique labels present in the train data are {Counter(y_train)}')\n",
    "print(f'Unique labels present in the test data are {Counter(y_test)}')\n",
    "\n",
    "#NOTE:- For multiclass classification we need to convert the binary ordinal labels to OHE (one-hot-encoded) labels.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15945f0c",
   "metadata": {},
   "source": [
    "In the first part of this assignment the aim is to identify whether the wafer map contains any known patterns or not. We therefore treat it as a binary classification problem and replace labels other than 0 to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "420f1d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_binary_train = np.copy(y_train)\n",
    "y_binary_train[y_binary_train != 0] = 1\n",
    "\n",
    "y_binary_test = np.copy(y_test)\n",
    "y_binary_test[y_binary_test != 0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c3a8766",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Even before we do this, we need to create a validation dataset to achieve our training objective\n",
    "\n",
    "#We will create the validation set from the training data itsellf as we do not intend to leak the test in any manner\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_binary_train, y_binary_val = train_test_split(X_train, y_binary_train, test_size = 0.1, random_state =42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04758e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the validation data is (431, 26, 26)\n",
      "The shape of the validation targets is (431,)\n",
      "The shape of a wafer image in validation dataset is (26, 26)\n",
      "\n",
      "\n",
      "The shape of the new train data is (3879, 26, 26)\n"
     ]
    }
   ],
   "source": [
    "print(f'The shape of the validation data is {X_val.shape}') #3D array\n",
    "print(f'The shape of the validation targets is {y_binary_val.shape}')\n",
    "print(f'The shape of a wafer image in validation dataset is {X_val[0].shape}')\n",
    "print('\\n')\n",
    "print(f'The shape of the new train data is {X_train.shape}') #3D array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d5bd279",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the dataset class here\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader,TensorDataset\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "\n",
    "#creating the dataset class for binary classification\n",
    "\n",
    "\n",
    "class DatasetBinary(Dataset):\n",
    "    def __init__(self, data, targets):\n",
    "        self.data = torch.FloatTensor(data)\n",
    "        self.targets = torch.Tensor(targets)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index]\n",
    "        y = self.targets[index]\n",
    "        \n",
    "        return x, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self.data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ba3e7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the dataset\n",
    "train_dataset_binary = DatasetBinary(X_train, y_binary_train)\n",
    "test_dataset_binary = DatasetBinary(X_test, y_binary_test )\n",
    "validation_dataset_binary = DatasetBinary(X_val, y_binary_val)\n",
    "\n",
    "#creating the dataloaders\n",
    "\n",
    "train_dataloader_binary = torch.utils.data.DataLoader(train_dataset_binary, batch_size =10)\n",
    "test_dataloader_binary = torch.utils.data.DataLoader(test_dataset_binary, batch_size = 10)\n",
    "val_dataloader_binary = torch.utils.data.DataLoader(validation_dataset_binary, batch_size = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c08eebfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26, 26)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking the shape of the first image\n",
    "X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "36f12f72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3ec77da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the classifier \n",
    "#Given the data we shoould also look for augmentation techniques but let us explore this on the initial performance of the classiier\n",
    "#we will use a simple CNN initiallly and then see how this goes.\n",
    "\n",
    "#creating a VGG-16 inspired architecture \n",
    "\n",
    "class CNN_Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "            super(CNN_Classifier, self).__init__()\n",
    "\n",
    "            # Setting up the Sequential of CNN Layers\n",
    "            self.cnn1 = nn.Sequential(\n",
    "                nn.Conv2d(1, 96, kernel_size=3,stride=1),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.MaxPool2d(2, stride=2),\n",
    "\n",
    "                nn.Conv2d(96, 256, kernel_size=3, stride=1),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.MaxPool2d(2, stride=2),\n",
    "\n",
    "                nn.Conv2d(256, 384, kernel_size=3,stride=1),\n",
    "                nn.ReLU(inplace=True)\n",
    "            )\n",
    "\n",
    "            # Setting up the Fully Connected Layers\n",
    "            self.fc1 = nn.Sequential(\n",
    "                nn.Linear(384 * 3 * 3, 1024),\n",
    "                nn.ReLU(inplace=True),\n",
    "\n",
    "                nn.Linear(1024, 256),\n",
    "                nn.ReLU(inplace=True),\n",
    "                \n",
    "                nn.Linear(256,1),\n",
    "                nn.Sigmoid()\n",
    "            )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        output = self.cnn1(x)\n",
    "        output = output.view(output.size()[0], -1)\n",
    "        output = self.fc1(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "44a27919",
   "metadata": {},
   "outputs": [],
   "source": [
    "#write the trainer here (Training on the GPU)\n",
    "\n",
    "def save_model_checkpoint(path, model, optimizer, val_loss ):\n",
    "    if path == None:\n",
    "        return print(\"Kindly define a path\")\n",
    "    path = path\n",
    "    \n",
    "    save_dict = {\"model_dict\" : model.state_dict(), \n",
    "                 \"optimizer_dict\": optimizer.state_dict(),\n",
    "                 \"val_loss_dict\": val_loss}\n",
    "    torch.save(save_dict, path)\n",
    "    return print(\"Model Saved to ==> {}\".format(path) + \"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "def train(model, train_loader, val_loader, num_epochs, criterion, batch_size, device, path):\n",
    "    best_val_loss = float(\"Inf\")\n",
    "    train_loss, val_loss, train_acc, val_acc  = [], [], [], []\n",
    "    train_acc_list, val_acc_list = [], []\n",
    "    cur_step = 0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        running_train_loss = 0.0 #Clear the runnning loss/acc for every epoch\n",
    "\n",
    "        #For the train dataset\n",
    "        for i, data in enumerate(train_loader):\n",
    "            inp, targets = data\n",
    "            inp = torch.unsqueeze(inp,1).to(device)\n",
    "            curr_train_loss= 0.0 # we need to clear the loss for every batch\n",
    "            output = model.forward(inp)\n",
    "            curr_train_loss = criterion(output.squeeze(1), targets.cuda()).to(device)\n",
    "            train_loss.append(curr_train_loss)\n",
    "            \n",
    "            running_train_loss +=curr_train_loss\n",
    "\n",
    "            curr_train_acc = torch.sum(targets.cuda() == torch.round(output)).to(device) #batch_accuracy\n",
    "            train_acc.append(curr_train_acc)\n",
    "            ##\n",
    "            train_acc_list.append(curr_train_acc)\n",
    "\n",
    "            #Make the backward step\n",
    "            optimizer.zero_grad()\n",
    "            curr_train_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        #start the validation procedure\n",
    "        running_val_loss = 0.0 #we need to clear the running_val_loss for every epoch\n",
    "      \n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            for j, val_data in enumerate(val_loader):\n",
    "                val_inp, val_targets = val_data\n",
    "                val_inp = torch.unsqueeze(val_inp,1).to(device)\n",
    "                curr_val_loss = 0.0 # we need to clear the val loss for every batch\n",
    "                val_output = model.forward(val_inp)\n",
    "                curr_val_loss = criterion(val_output.squeeze(1), val_targets.cuda()).to(device)\n",
    "                val_loss.append(curr_val_loss)\n",
    "                \n",
    "                #curr_val_acc = torch.sum(torch.eq(val_targets, torch.round(val_output)))\n",
    "                curr_val_acc = torch.sum(val_targets.cuda() == torch.round(val_output)).to(device)\n",
    "                val_acc.append(curr_val_acc)\n",
    "\n",
    "                running_val_loss += curr_val_loss\n",
    "                \n",
    "                val_acc_list.append(curr_val_acc)\n",
    "                \n",
    "                \n",
    "\n",
    "        avg_train_loss = running_train_loss/len(train_loader)\n",
    "        avg_val_loss = running_val_loss/len(val_loader)    \n",
    "        \n",
    "        print('Epoch [{}/{}],Train Loss: {:.4f}, Valid Loss: {:.8f}'.format(epoch+1, num_epochs, avg_train_loss, avg_val_loss))\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            save_model_checkpoint(path, model, optimizer, best_val_loss)\n",
    "        \n",
    "    print('Finished Training Procedure')\n",
    "    return train_loss, val_loss, train_acc_list, val_acc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "08eab1c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/600],Train Loss: 0.3634, Valid Loss: 0.29470921\n",
      "Model Saved to ==> /home/ambarish/Documents/2IMN30 ML IND/calibration/models/binary_classification_model.pt\n",
      "\n",
      "Epoch [2/600],Train Loss: 0.3218, Valid Loss: 0.26517344\n",
      "Model Saved to ==> /home/ambarish/Documents/2IMN30 ML IND/calibration/models/binary_classification_model.pt\n",
      "\n",
      "Epoch [3/600],Train Loss: 0.3032, Valid Loss: 0.26038042\n",
      "Model Saved to ==> /home/ambarish/Documents/2IMN30 ML IND/calibration/models/binary_classification_model.pt\n",
      "\n",
      "Epoch [4/600],Train Loss: 0.2860, Valid Loss: 0.25206628\n",
      "Model Saved to ==> /home/ambarish/Documents/2IMN30 ML IND/calibration/models/binary_classification_model.pt\n",
      "\n",
      "Epoch [5/600],Train Loss: 0.2667, Valid Loss: 0.23184979\n",
      "Model Saved to ==> /home/ambarish/Documents/2IMN30 ML IND/calibration/models/binary_classification_model.pt\n",
      "\n",
      "Epoch [6/600],Train Loss: 0.2432, Valid Loss: 0.20985454\n",
      "Model Saved to ==> /home/ambarish/Documents/2IMN30 ML IND/calibration/models/binary_classification_model.pt\n",
      "\n",
      "Epoch [7/600],Train Loss: 0.2095, Valid Loss: 0.20768760\n",
      "Model Saved to ==> /home/ambarish/Documents/2IMN30 ML IND/calibration/models/binary_classification_model.pt\n",
      "\n",
      "Epoch [8/600],Train Loss: 0.1805, Valid Loss: 0.16264820\n",
      "Model Saved to ==> /home/ambarish/Documents/2IMN30 ML IND/calibration/models/binary_classification_model.pt\n",
      "\n",
      "Epoch [9/600],Train Loss: 0.1459, Valid Loss: 0.15978611\n",
      "Model Saved to ==> /home/ambarish/Documents/2IMN30 ML IND/calibration/models/binary_classification_model.pt\n",
      "\n",
      "Epoch [10/600],Train Loss: 0.1307, Valid Loss: 0.14848472\n",
      "Model Saved to ==> /home/ambarish/Documents/2IMN30 ML IND/calibration/models/binary_classification_model.pt\n",
      "\n",
      "Epoch [11/600],Train Loss: 0.1063, Valid Loss: 0.17791086\n",
      "Epoch [12/600],Train Loss: 0.0889, Valid Loss: 0.31149617\n",
      "Epoch [13/600],Train Loss: 0.0646, Valid Loss: 0.17835820\n",
      "Epoch [14/600],Train Loss: 0.0631, Valid Loss: 0.16522695\n",
      "Epoch [15/600],Train Loss: 0.0541, Valid Loss: 0.29541862\n",
      "Epoch [16/600],Train Loss: 0.0379, Valid Loss: 0.31924209\n",
      "Epoch [17/600],Train Loss: 0.0276, Valid Loss: 0.36525488\n",
      "Epoch [18/600],Train Loss: 0.0279, Valid Loss: 0.25509810\n",
      "Epoch [19/600],Train Loss: 0.0312, Valid Loss: 0.24710663\n",
      "Epoch [20/600],Train Loss: 0.0261, Valid Loss: 0.34455341\n",
      "Epoch [21/600],Train Loss: 0.0165, Valid Loss: 0.28542292\n",
      "Epoch [22/600],Train Loss: 0.0157, Valid Loss: 0.29459736\n",
      "Epoch [23/600],Train Loss: 0.0219, Valid Loss: 0.42240599\n",
      "Epoch [24/600],Train Loss: 0.0282, Valid Loss: 0.25389084\n",
      "Epoch [25/600],Train Loss: 0.0165, Valid Loss: 0.30640665\n",
      "Epoch [26/600],Train Loss: 0.0109, Valid Loss: 0.34520572\n",
      "Epoch [27/600],Train Loss: 0.0197, Valid Loss: 0.24431579\n",
      "Epoch [28/600],Train Loss: 0.0161, Valid Loss: 0.28444940\n",
      "Epoch [29/600],Train Loss: 0.0149, Valid Loss: 0.19325437\n",
      "Epoch [30/600],Train Loss: 0.0052, Valid Loss: 0.31254166\n",
      "Epoch [31/600],Train Loss: 0.0102, Valid Loss: 0.26619297\n",
      "Epoch [32/600],Train Loss: 0.0013, Valid Loss: 0.34955335\n",
      "Epoch [33/600],Train Loss: 0.0008, Valid Loss: 0.34998035\n",
      "Epoch [34/600],Train Loss: 0.0006, Valid Loss: 0.70056850\n",
      "Epoch [35/600],Train Loss: 0.0485, Valid Loss: 0.24938869\n",
      "Epoch [36/600],Train Loss: 0.0186, Valid Loss: 0.26066440\n",
      "Epoch [37/600],Train Loss: 0.0126, Valid Loss: 0.28774771\n",
      "Epoch [38/600],Train Loss: 0.0107, Valid Loss: 0.33474860\n",
      "Epoch [39/600],Train Loss: 0.0170, Valid Loss: 0.28955182\n",
      "Epoch [40/600],Train Loss: 0.0130, Valid Loss: 0.60857862\n",
      "Epoch [41/600],Train Loss: 0.0321, Valid Loss: 0.55991679\n",
      "Epoch [42/600],Train Loss: 0.0107, Valid Loss: 0.30242330\n",
      "Epoch [43/600],Train Loss: 0.0135, Valid Loss: 0.32554427\n",
      "Epoch [44/600],Train Loss: 0.0053, Valid Loss: 0.40457207\n",
      "Epoch [45/600],Train Loss: 0.0126, Valid Loss: 0.32849547\n",
      "Epoch [46/600],Train Loss: 0.0204, Valid Loss: 0.49335179\n",
      "Epoch [47/600],Train Loss: 0.0241, Valid Loss: 0.34279984\n",
      "Epoch [48/600],Train Loss: 0.0109, Valid Loss: 0.38582587\n",
      "Epoch [49/600],Train Loss: 0.0047, Valid Loss: 0.55984163\n",
      "Epoch [50/600],Train Loss: 0.0341, Valid Loss: 0.31763679\n",
      "Epoch [51/600],Train Loss: 0.0204, Valid Loss: 0.23384881\n",
      "Epoch [52/600],Train Loss: 0.0079, Valid Loss: 0.38443041\n",
      "Epoch [53/600],Train Loss: 0.0008, Valid Loss: 0.47488245\n",
      "Epoch [54/600],Train Loss: 0.0004, Valid Loss: 0.72584373\n",
      "Epoch [55/600],Train Loss: 0.0004, Valid Loss: 0.75660837\n",
      "Epoch [56/600],Train Loss: 0.0004, Valid Loss: 0.77477139\n",
      "Epoch [57/600],Train Loss: 0.0004, Valid Loss: 0.79492635\n",
      "Epoch [58/600],Train Loss: 0.0004, Valid Loss: 0.81222439\n",
      "Epoch [59/600],Train Loss: 0.0004, Valid Loss: 0.82259572\n",
      "Epoch [60/600],Train Loss: 0.0004, Valid Loss: 0.83391047\n",
      "Epoch [61/600],Train Loss: 0.0004, Valid Loss: 0.84690702\n",
      "Epoch [62/600],Train Loss: 0.0004, Valid Loss: 0.85646236\n",
      "Epoch [63/600],Train Loss: 0.0004, Valid Loss: 0.86895818\n",
      "Epoch [64/600],Train Loss: 0.0004, Valid Loss: 0.85270798\n",
      "Epoch [65/600],Train Loss: 0.0004, Valid Loss: 0.89551598\n",
      "Epoch [66/600],Train Loss: 0.0004, Valid Loss: 0.90957940\n",
      "Epoch [67/600],Train Loss: 0.0004, Valid Loss: 0.91321462\n",
      "Epoch [68/600],Train Loss: 0.0004, Valid Loss: 1.13479614\n",
      "Epoch [69/600],Train Loss: 0.0004, Valid Loss: 1.15518475\n",
      "Epoch [70/600],Train Loss: 0.0004, Valid Loss: 1.17243505\n",
      "Epoch [71/600],Train Loss: 0.0004, Valid Loss: 1.19302487\n",
      "Epoch [72/600],Train Loss: 0.0004, Valid Loss: 1.22867692\n",
      "Epoch [73/600],Train Loss: 0.0004, Valid Loss: 1.24736178\n",
      "Epoch [74/600],Train Loss: 0.0004, Valid Loss: 1.27796233\n",
      "Epoch [75/600],Train Loss: 0.0004, Valid Loss: 1.52621222\n",
      "Epoch [76/600],Train Loss: 0.0781, Valid Loss: 0.37582159\n",
      "Epoch [77/600],Train Loss: 0.0353, Valid Loss: 0.50722134\n",
      "Epoch [78/600],Train Loss: 0.0155, Valid Loss: 0.32905450\n",
      "Epoch [79/600],Train Loss: 0.0037, Valid Loss: 0.68865585\n",
      "Epoch [80/600],Train Loss: 0.0017, Valid Loss: 0.72360641\n",
      "Epoch [81/600],Train Loss: 0.0006, Valid Loss: 0.75553387\n",
      "Epoch [82/600],Train Loss: 0.0006, Valid Loss: 0.71036685\n",
      "Epoch [83/600],Train Loss: 0.0004, Valid Loss: 0.75351405\n",
      "Epoch [84/600],Train Loss: 0.0004, Valid Loss: 0.77852607\n",
      "Epoch [85/600],Train Loss: 0.0004, Valid Loss: 0.79647344\n",
      "Epoch [86/600],Train Loss: 0.0004, Valid Loss: 0.81098306\n",
      "Epoch [87/600],Train Loss: 0.0004, Valid Loss: 0.81817693\n",
      "Epoch [88/600],Train Loss: 0.0004, Valid Loss: 0.82703388\n",
      "Epoch [89/600],Train Loss: 0.0004, Valid Loss: 0.83336920\n",
      "Epoch [90/600],Train Loss: 0.0004, Valid Loss: 0.84902048\n",
      "Epoch [91/600],Train Loss: 0.0004, Valid Loss: 0.85698730\n",
      "Epoch [92/600],Train Loss: 0.0004, Valid Loss: 0.87696087\n",
      "Epoch [93/600],Train Loss: 0.0004, Valid Loss: 0.90024567\n",
      "Epoch [94/600],Train Loss: 0.0004, Valid Loss: 0.91274506\n",
      "Epoch [95/600],Train Loss: 0.0004, Valid Loss: 0.94540626\n",
      "Epoch [96/600],Train Loss: 0.0004, Valid Loss: 0.96362048\n",
      "Epoch [97/600],Train Loss: 0.0004, Valid Loss: 0.97058004\n",
      "Epoch [98/600],Train Loss: 0.0004, Valid Loss: 0.98233938\n",
      "Epoch [99/600],Train Loss: 0.0004, Valid Loss: 0.97405255\n",
      "Epoch [100/600],Train Loss: 0.0004, Valid Loss: 1.00449955\n",
      "Epoch [101/600],Train Loss: 0.0004, Valid Loss: 1.04132283\n",
      "Epoch [102/600],Train Loss: 0.0004, Valid Loss: 1.03780949\n",
      "Epoch [103/600],Train Loss: 0.0004, Valid Loss: 1.04967594\n",
      "Epoch [104/600],Train Loss: 0.0004, Valid Loss: 1.07019281\n",
      "Epoch [105/600],Train Loss: 0.0004, Valid Loss: 1.09933126\n",
      "Epoch [106/600],Train Loss: 0.0004, Valid Loss: 1.27882195\n",
      "Epoch [107/600],Train Loss: 0.0004, Valid Loss: 1.30476153\n",
      "Epoch [108/600],Train Loss: 0.0004, Valid Loss: 1.32658041\n",
      "Epoch [109/600],Train Loss: 0.0004, Valid Loss: 1.15657079\n",
      "Epoch [110/600],Train Loss: 0.0004, Valid Loss: 1.18772650\n",
      "Epoch [111/600],Train Loss: 0.0004, Valid Loss: 1.17250478\n",
      "Epoch [112/600],Train Loss: 0.1225, Valid Loss: 0.27009645\n",
      "Epoch [113/600],Train Loss: 0.0334, Valid Loss: 0.62994337\n",
      "Epoch [114/600],Train Loss: 0.0306, Valid Loss: 0.51950794\n",
      "Epoch [115/600],Train Loss: 0.0106, Valid Loss: 0.71913606\n",
      "Epoch [116/600],Train Loss: 0.0104, Valid Loss: 0.41935977\n",
      "Epoch [117/600],Train Loss: 0.0077, Valid Loss: 0.73553997\n",
      "Epoch [118/600],Train Loss: 0.0064, Valid Loss: 0.74167114\n",
      "Epoch [119/600],Train Loss: 0.0009, Valid Loss: 1.24741805\n",
      "Epoch [120/600],Train Loss: 0.0021, Valid Loss: 0.90221280\n",
      "Epoch [121/600],Train Loss: 0.0004, Valid Loss: 1.02162135\n",
      "Epoch [122/600],Train Loss: 0.0004, Valid Loss: 1.08057904\n",
      "Epoch [123/600],Train Loss: 0.0004, Valid Loss: 1.11322868\n",
      "Epoch [124/600],Train Loss: 0.0004, Valid Loss: 1.13844168\n",
      "Epoch [125/600],Train Loss: 0.0004, Valid Loss: 1.11839771\n",
      "Epoch [126/600],Train Loss: 0.0004, Valid Loss: 1.15912282\n",
      "Epoch [127/600],Train Loss: 0.0004, Valid Loss: 1.18993282\n",
      "Epoch [128/600],Train Loss: 0.0004, Valid Loss: 1.21170282\n",
      "Epoch [129/600],Train Loss: 0.0004, Valid Loss: 1.22752357\n",
      "Epoch [130/600],Train Loss: 0.0004, Valid Loss: 1.43563032\n",
      "Epoch [131/600],Train Loss: 0.0004, Valid Loss: 1.44635427\n",
      "Epoch [132/600],Train Loss: 0.0004, Valid Loss: 1.45245945\n",
      "Epoch [133/600],Train Loss: 0.0004, Valid Loss: 1.46553600\n",
      "Epoch [134/600],Train Loss: 0.0004, Valid Loss: 1.48481274\n",
      "Epoch [135/600],Train Loss: 0.0004, Valid Loss: 1.48802972\n",
      "Epoch [136/600],Train Loss: 0.0004, Valid Loss: 1.50977612\n",
      "Epoch [137/600],Train Loss: 0.0004, Valid Loss: 1.51390076\n",
      "Epoch [138/600],Train Loss: 0.0004, Valid Loss: 1.53130901\n",
      "Epoch [139/600],Train Loss: 0.0004, Valid Loss: 1.54428017\n",
      "Epoch [140/600],Train Loss: 0.0004, Valid Loss: 1.55244386\n",
      "Epoch [141/600],Train Loss: 0.0834, Valid Loss: 0.20422390\n",
      "Epoch [142/600],Train Loss: 0.0233, Valid Loss: 0.65051395\n",
      "Epoch [143/600],Train Loss: 0.0270, Valid Loss: 0.67666727\n",
      "Epoch [144/600],Train Loss: 0.0064, Valid Loss: 0.63728464\n",
      "Epoch [145/600],Train Loss: 0.0013, Valid Loss: 0.99997246\n",
      "Epoch [146/600],Train Loss: 0.0005, Valid Loss: 1.02677631\n",
      "Epoch [147/600],Train Loss: 0.0004, Valid Loss: 1.17095912\n",
      "Epoch [148/600],Train Loss: 0.0004, Valid Loss: 1.17524099\n",
      "Epoch [149/600],Train Loss: 0.0004, Valid Loss: 1.20138609\n",
      "Epoch [150/600],Train Loss: 0.0004, Valid Loss: 1.23873723\n",
      "Epoch [151/600],Train Loss: 0.0004, Valid Loss: 1.46845186\n",
      "Epoch [152/600],Train Loss: 0.0004, Valid Loss: 1.51101303\n",
      "Epoch [153/600],Train Loss: 0.0004, Valid Loss: 1.49513841\n",
      "Epoch [154/600],Train Loss: 0.0004, Valid Loss: 1.53073645\n",
      "Epoch [155/600],Train Loss: 0.0004, Valid Loss: 1.54619920\n",
      "Epoch [156/600],Train Loss: 0.0004, Valid Loss: 1.48092568\n",
      "Epoch [157/600],Train Loss: 0.0004, Valid Loss: 1.57086027\n",
      "Epoch [158/600],Train Loss: 0.0004, Valid Loss: 1.58879030\n",
      "Epoch [159/600],Train Loss: 0.0004, Valid Loss: 1.69188678\n",
      "Epoch [160/600],Train Loss: 0.0004, Valid Loss: 1.60902619\n",
      "Epoch [161/600],Train Loss: 0.0004, Valid Loss: 1.61369669\n",
      "Epoch [162/600],Train Loss: 0.0004, Valid Loss: 1.63473928\n",
      "Epoch [163/600],Train Loss: 0.0707, Valid Loss: 0.19909124\n",
      "Epoch [164/600],Train Loss: 0.0293, Valid Loss: 0.31003761\n",
      "Epoch [165/600],Train Loss: 0.0200, Valid Loss: 0.31863293\n",
      "Epoch [166/600],Train Loss: 0.0112, Valid Loss: 0.39793053\n",
      "Epoch [167/600],Train Loss: 0.0042, Valid Loss: 0.49289063\n",
      "Epoch [168/600],Train Loss: 0.0131, Valid Loss: 0.34758559\n",
      "Epoch [169/600],Train Loss: 0.0191, Valid Loss: 0.46169376\n",
      "Epoch [170/600],Train Loss: 0.0111, Valid Loss: 0.56906492\n",
      "Epoch [171/600],Train Loss: 0.0014, Valid Loss: 0.67201072\n",
      "Epoch [172/600],Train Loss: 0.0035, Valid Loss: 0.56029993\n",
      "Epoch [173/600],Train Loss: 0.0081, Valid Loss: 0.38345155\n",
      "Epoch [174/600],Train Loss: 0.0017, Valid Loss: 0.64492947\n",
      "Epoch [175/600],Train Loss: 0.0005, Valid Loss: 0.67125100\n",
      "Epoch [176/600],Train Loss: 0.0004, Valid Loss: 0.68929869\n",
      "Epoch [177/600],Train Loss: 0.0004, Valid Loss: 0.70463431\n",
      "Epoch [178/600],Train Loss: 0.0004, Valid Loss: 0.71508884\n",
      "Epoch [179/600],Train Loss: 0.0004, Valid Loss: 0.72974205\n",
      "Epoch [180/600],Train Loss: 0.0004, Valid Loss: 0.74287337\n",
      "Epoch [181/600],Train Loss: 0.0004, Valid Loss: 0.75743771\n",
      "Epoch [182/600],Train Loss: 0.0004, Valid Loss: 0.76495492\n",
      "Epoch [183/600],Train Loss: 0.0004, Valid Loss: 0.77761930\n",
      "Epoch [184/600],Train Loss: 0.0004, Valid Loss: 0.79234982\n",
      "Epoch [185/600],Train Loss: 0.0004, Valid Loss: 0.80605042\n",
      "Epoch [186/600],Train Loss: 0.0004, Valid Loss: 0.81955260\n",
      "Epoch [187/600],Train Loss: 0.0004, Valid Loss: 0.83126575\n",
      "Epoch [188/600],Train Loss: 0.0004, Valid Loss: 0.83949655\n",
      "Epoch [189/600],Train Loss: 0.0004, Valid Loss: 0.85373551\n",
      "Epoch [190/600],Train Loss: 0.0004, Valid Loss: 0.82504553\n",
      "Epoch [191/600],Train Loss: 0.0004, Valid Loss: 0.88993776\n",
      "Epoch [192/600],Train Loss: 0.0994, Valid Loss: 0.56691968\n",
      "Epoch [193/600],Train Loss: 0.0128, Valid Loss: 0.63780099\n",
      "Epoch [194/600],Train Loss: 0.0104, Valid Loss: 0.55336648\n",
      "Epoch [195/600],Train Loss: 0.0007, Valid Loss: 0.59414369\n",
      "Epoch [196/600],Train Loss: 0.0004, Valid Loss: 0.61523873\n",
      "Epoch [197/600],Train Loss: 0.0004, Valid Loss: 0.62606680\n",
      "Epoch [198/600],Train Loss: 0.0004, Valid Loss: 0.62690258\n",
      "Epoch [199/600],Train Loss: 0.0004, Valid Loss: 0.64599329\n",
      "Epoch [200/600],Train Loss: 0.0004, Valid Loss: 0.66255796\n",
      "Epoch [201/600],Train Loss: 0.0004, Valid Loss: 0.66106856\n",
      "Epoch [202/600],Train Loss: 0.0004, Valid Loss: 0.66549426\n",
      "Epoch [203/600],Train Loss: 0.0004, Valid Loss: 0.69181842\n",
      "Epoch [204/600],Train Loss: 0.0004, Valid Loss: 0.69935560\n",
      "Epoch [205/600],Train Loss: 0.0004, Valid Loss: 0.71628755\n",
      "Epoch [206/600],Train Loss: 0.0004, Valid Loss: 0.72049725\n",
      "Epoch [207/600],Train Loss: 0.0004, Valid Loss: 0.74287969\n",
      "Epoch [208/600],Train Loss: 0.0004, Valid Loss: 0.76205420\n",
      "Epoch [209/600],Train Loss: 0.0004, Valid Loss: 0.77620310\n",
      "Epoch [210/600],Train Loss: 0.0004, Valid Loss: 0.79724342\n",
      "Epoch [211/600],Train Loss: 0.0004, Valid Loss: 0.80442923\n",
      "Epoch [212/600],Train Loss: 0.0004, Valid Loss: 0.82484788\n",
      "Epoch [213/600],Train Loss: 0.0004, Valid Loss: 0.83545166\n",
      "Epoch [214/600],Train Loss: 0.0004, Valid Loss: 0.85496593\n",
      "Epoch [215/600],Train Loss: 0.0004, Valid Loss: 0.87251824\n",
      "Epoch [216/600],Train Loss: 0.0004, Valid Loss: 0.89703155\n",
      "Epoch [217/600],Train Loss: 0.0004, Valid Loss: 0.88574350\n",
      "Epoch [218/600],Train Loss: 0.0004, Valid Loss: 0.90594703\n",
      "Epoch [219/600],Train Loss: 0.0004, Valid Loss: 0.92188346\n",
      "Epoch [220/600],Train Loss: 0.0004, Valid Loss: 0.93523121\n",
      "Epoch [221/600],Train Loss: 0.0004, Valid Loss: 0.94685966\n",
      "Epoch [222/600],Train Loss: 0.0004, Valid Loss: 0.95871449\n",
      "Epoch [223/600],Train Loss: 0.0563, Valid Loss: 0.37390047\n",
      "Epoch [224/600],Train Loss: 0.0577, Valid Loss: 0.30455345\n",
      "Epoch [225/600],Train Loss: 0.0043, Valid Loss: 0.74886447\n",
      "Epoch [226/600],Train Loss: 0.0010, Valid Loss: 1.14547157\n",
      "Epoch [227/600],Train Loss: 0.0007, Valid Loss: 0.76312751\n",
      "Epoch [228/600],Train Loss: 0.0005, Valid Loss: 1.13225985\n",
      "Epoch [229/600],Train Loss: 0.0243, Valid Loss: 0.27804339\n",
      "Epoch [230/600],Train Loss: 0.0129, Valid Loss: 0.52308482\n",
      "Epoch [231/600],Train Loss: 0.0059, Valid Loss: 0.61844653\n",
      "Epoch [232/600],Train Loss: 0.0014, Valid Loss: 1.03562129\n",
      "Epoch [233/600],Train Loss: 0.0133, Valid Loss: 0.45550552\n",
      "Epoch [234/600],Train Loss: 0.0015, Valid Loss: 0.85378969\n",
      "Epoch [235/600],Train Loss: 0.0006, Valid Loss: 0.93277615\n",
      "Epoch [236/600],Train Loss: 0.0006, Valid Loss: 1.20922720\n",
      "Epoch [237/600],Train Loss: 0.0251, Valid Loss: 0.85944706\n",
      "Epoch [238/600],Train Loss: 0.0113, Valid Loss: 0.85752249\n",
      "Epoch [239/600],Train Loss: 0.0005, Valid Loss: 1.06757140\n",
      "Epoch [240/600],Train Loss: 0.0004, Valid Loss: 1.12745821\n",
      "Epoch [241/600],Train Loss: 0.0004, Valid Loss: 1.13454056\n",
      "Epoch [242/600],Train Loss: 0.0004, Valid Loss: 1.14140069\n",
      "Epoch [243/600],Train Loss: 0.0004, Valid Loss: 1.14751947\n",
      "Epoch [244/600],Train Loss: 0.0004, Valid Loss: 1.15454245\n",
      "Epoch [245/600],Train Loss: 0.0004, Valid Loss: 1.16150510\n",
      "Epoch [246/600],Train Loss: 0.0004, Valid Loss: 1.16800022\n",
      "Epoch [247/600],Train Loss: 0.0004, Valid Loss: 1.16002488\n",
      "Epoch [248/600],Train Loss: 0.0004, Valid Loss: 1.18886721\n",
      "Epoch [249/600],Train Loss: 0.0004, Valid Loss: 1.18954790\n",
      "Epoch [250/600],Train Loss: 0.0004, Valid Loss: 1.20219243\n",
      "Epoch [251/600],Train Loss: 0.0004, Valid Loss: 1.21387386\n",
      "Epoch [252/600],Train Loss: 0.0004, Valid Loss: 1.22386670\n",
      "Epoch [253/600],Train Loss: 0.0004, Valid Loss: 1.20604634\n",
      "Epoch [254/600],Train Loss: 0.0004, Valid Loss: 1.23798513\n",
      "Epoch [255/600],Train Loss: 0.0004, Valid Loss: 1.25695705\n",
      "Epoch [256/600],Train Loss: 0.0004, Valid Loss: 1.26589084\n",
      "Epoch [257/600],Train Loss: 0.0004, Valid Loss: 1.27237666\n",
      "Epoch [258/600],Train Loss: 0.0004, Valid Loss: 1.27759695\n",
      "Epoch [259/600],Train Loss: 0.0004, Valid Loss: 1.28125095\n",
      "Epoch [260/600],Train Loss: 0.0004, Valid Loss: 1.28700089\n",
      "Epoch [261/600],Train Loss: 0.0004, Valid Loss: 1.28936279\n",
      "Epoch [262/600],Train Loss: 0.0004, Valid Loss: 1.29279423\n",
      "Epoch [263/600],Train Loss: 0.0004, Valid Loss: 1.32177603\n",
      "Epoch [264/600],Train Loss: 0.0004, Valid Loss: 1.31315613\n",
      "Epoch [265/600],Train Loss: 0.0004, Valid Loss: 1.31542361\n",
      "Epoch [266/600],Train Loss: 0.0004, Valid Loss: 1.30897200\n",
      "Epoch [267/600],Train Loss: 0.0004, Valid Loss: 1.31795192\n",
      "Epoch [268/600],Train Loss: 0.0004, Valid Loss: 1.32893324\n",
      "Epoch [269/600],Train Loss: 0.0004, Valid Loss: 1.33574831\n",
      "Epoch [270/600],Train Loss: 0.0004, Valid Loss: 1.54310679\n",
      "Epoch [271/600],Train Loss: 0.0413, Valid Loss: 0.48623461\n",
      "Epoch [272/600],Train Loss: 0.0309, Valid Loss: 0.48431492\n",
      "Epoch [273/600],Train Loss: 0.0064, Valid Loss: 1.06291366\n",
      "Epoch [274/600],Train Loss: 0.0313, Valid Loss: 0.59466982\n",
      "Epoch [275/600],Train Loss: 0.0048, Valid Loss: 0.69360155\n",
      "Epoch [276/600],Train Loss: 0.0008, Valid Loss: 0.70680827\n",
      "Epoch [277/600],Train Loss: 0.0005, Valid Loss: 0.73495537\n",
      "Epoch [278/600],Train Loss: 0.0004, Valid Loss: 0.76088083\n",
      "Epoch [279/600],Train Loss: 0.0004, Valid Loss: 0.78299332\n",
      "Epoch [280/600],Train Loss: 0.0004, Valid Loss: 0.82652617\n",
      "Epoch [281/600],Train Loss: 0.0004, Valid Loss: 0.86190444\n",
      "Epoch [282/600],Train Loss: 0.0004, Valid Loss: 0.89185894\n",
      "Epoch [283/600],Train Loss: 0.0004, Valid Loss: 0.91700828\n",
      "Epoch [284/600],Train Loss: 0.0004, Valid Loss: 0.93979949\n",
      "Epoch [285/600],Train Loss: 0.0258, Valid Loss: 0.66106242\n",
      "Epoch [286/600],Train Loss: 0.0270, Valid Loss: 0.64737254\n",
      "Epoch [287/600],Train Loss: 0.0076, Valid Loss: 1.07242382\n",
      "Epoch [288/600],Train Loss: 0.0006, Valid Loss: 1.08857441\n",
      "Epoch [289/600],Train Loss: 0.0005, Valid Loss: 1.14139271\n",
      "Epoch [290/600],Train Loss: 0.0005, Valid Loss: 1.18213868\n",
      "Epoch [291/600],Train Loss: 0.0004, Valid Loss: 1.28208220\n",
      "Epoch [292/600],Train Loss: 0.0005, Valid Loss: 1.10593081\n",
      "Epoch [293/600],Train Loss: 0.0006, Valid Loss: 0.76282269\n",
      "Epoch [294/600],Train Loss: 0.0296, Valid Loss: 0.39900330\n",
      "Epoch [295/600],Train Loss: 0.0055, Valid Loss: 0.77440542\n",
      "Epoch [296/600],Train Loss: 0.0091, Valid Loss: 0.63564122\n",
      "Epoch [297/600],Train Loss: 0.0059, Valid Loss: 0.72188127\n",
      "Epoch [298/600],Train Loss: 0.0088, Valid Loss: 0.86903244\n",
      "Epoch [299/600],Train Loss: 0.0004, Valid Loss: 1.11289096\n",
      "Epoch [300/600],Train Loss: 0.0004, Valid Loss: 1.13442695\n",
      "Epoch [301/600],Train Loss: 0.0004, Valid Loss: 1.34842908\n",
      "Epoch [302/600],Train Loss: 0.0004, Valid Loss: 1.35705328\n",
      "Epoch [303/600],Train Loss: 0.0004, Valid Loss: 1.39165080\n",
      "Epoch [304/600],Train Loss: 0.0005, Valid Loss: 0.90100086\n",
      "Epoch [305/600],Train Loss: 0.0004, Valid Loss: 1.22757196\n",
      "Epoch [306/600],Train Loss: 0.0004, Valid Loss: 1.25479996\n",
      "Epoch [307/600],Train Loss: 0.0004, Valid Loss: 1.26894653\n",
      "Epoch [308/600],Train Loss: 0.0004, Valid Loss: 1.27895033\n",
      "Epoch [309/600],Train Loss: 0.0004, Valid Loss: 1.30255437\n",
      "Epoch [310/600],Train Loss: 0.0004, Valid Loss: 1.87580180\n",
      "Epoch [311/600],Train Loss: 0.0383, Valid Loss: 0.96334237\n",
      "Epoch [312/600],Train Loss: 0.0320, Valid Loss: 0.91365784\n",
      "Epoch [313/600],Train Loss: 0.0012, Valid Loss: 1.65598083\n",
      "Epoch [314/600],Train Loss: 0.0004, Valid Loss: 1.30533397\n",
      "Epoch [315/600],Train Loss: 0.0004, Valid Loss: 1.34241879\n",
      "Epoch [316/600],Train Loss: 0.0004, Valid Loss: 1.36905837\n",
      "Epoch [317/600],Train Loss: 0.0004, Valid Loss: 1.58261025\n",
      "Epoch [318/600],Train Loss: 0.0004, Valid Loss: 1.60255611\n",
      "Epoch [319/600],Train Loss: 0.0004, Valid Loss: 1.60935247\n",
      "Epoch [320/600],Train Loss: 0.0004, Valid Loss: 1.62350154\n",
      "Epoch [321/600],Train Loss: 0.0004, Valid Loss: 1.62541449\n",
      "Epoch [322/600],Train Loss: 0.0004, Valid Loss: 1.63898420\n",
      "Epoch [323/600],Train Loss: 0.0004, Valid Loss: 1.62996781\n",
      "Epoch [324/600],Train Loss: 0.0004, Valid Loss: 1.64504409\n",
      "Epoch [325/600],Train Loss: 0.0004, Valid Loss: 1.65784073\n",
      "Epoch [326/600],Train Loss: 0.0004, Valid Loss: 1.86147571\n",
      "Epoch [327/600],Train Loss: 0.0004, Valid Loss: 1.86826837\n",
      "Epoch [328/600],Train Loss: 0.0004, Valid Loss: 1.97467446\n",
      "Epoch [329/600],Train Loss: 0.0004, Valid Loss: 1.68696165\n",
      "Epoch [330/600],Train Loss: 0.0259, Valid Loss: 0.69038033\n",
      "Epoch [331/600],Train Loss: 0.0397, Valid Loss: 0.49851966\n",
      "Epoch [332/600],Train Loss: 0.0041, Valid Loss: 0.67745119\n",
      "Epoch [333/600],Train Loss: 0.0006, Valid Loss: 0.95118135\n",
      "Epoch [334/600],Train Loss: 0.0005, Valid Loss: 0.73404175\n",
      "Epoch [335/600],Train Loss: 0.0004, Valid Loss: 0.76261073\n",
      "Epoch [336/600],Train Loss: 0.0004, Valid Loss: 0.81913757\n",
      "Epoch [337/600],Train Loss: 0.0004, Valid Loss: 0.85218066\n",
      "Epoch [338/600],Train Loss: 0.0004, Valid Loss: 0.88555408\n",
      "Epoch [339/600],Train Loss: 0.0004, Valid Loss: 0.90671343\n",
      "Epoch [340/600],Train Loss: 0.0004, Valid Loss: 0.92308593\n",
      "Epoch [341/600],Train Loss: 0.0004, Valid Loss: 0.93587637\n",
      "Epoch [342/600],Train Loss: 0.0004, Valid Loss: 0.94317788\n",
      "Epoch [343/600],Train Loss: 0.0004, Valid Loss: 0.91402960\n",
      "Epoch [344/600],Train Loss: 0.0004, Valid Loss: 0.92881906\n",
      "Epoch [345/600],Train Loss: 0.0004, Valid Loss: 0.95864439\n",
      "Epoch [346/600],Train Loss: 0.0004, Valid Loss: 0.97335547\n",
      "Epoch [347/600],Train Loss: 0.0004, Valid Loss: 0.98406154\n",
      "Epoch [348/600],Train Loss: 0.0004, Valid Loss: 0.93677282\n",
      "Epoch [349/600],Train Loss: 0.0004, Valid Loss: 0.99123430\n",
      "Epoch [350/600],Train Loss: 0.0004, Valid Loss: 1.20101953\n",
      "Epoch [351/600],Train Loss: 0.0004, Valid Loss: 1.20352101\n",
      "Epoch [352/600],Train Loss: 0.0004, Valid Loss: 1.40704608\n",
      "Epoch [353/600],Train Loss: 0.0004, Valid Loss: 1.41241968\n",
      "Epoch [354/600],Train Loss: 0.0004, Valid Loss: 1.44365180\n",
      "Epoch [355/600],Train Loss: 0.0004, Valid Loss: 1.45385683\n",
      "Epoch [356/600],Train Loss: 0.0004, Valid Loss: 1.47002780\n",
      "Epoch [357/600],Train Loss: 0.0004, Valid Loss: 1.49209976\n",
      "Epoch [358/600],Train Loss: 0.0004, Valid Loss: 1.60578489\n",
      "Epoch [359/600],Train Loss: 0.0004, Valid Loss: 1.87018776\n",
      "Epoch [360/600],Train Loss: 0.0435, Valid Loss: 1.02403438\n",
      "Epoch [361/600],Train Loss: 0.0151, Valid Loss: 0.83172107\n",
      "Epoch [362/600],Train Loss: 0.0077, Valid Loss: 0.58879697\n",
      "Epoch [363/600],Train Loss: 0.0040, Valid Loss: 1.05280507\n",
      "Epoch [364/600],Train Loss: 0.0008, Valid Loss: 1.27791333\n",
      "Epoch [365/600],Train Loss: 0.0273, Valid Loss: 0.53015721\n",
      "Epoch [366/600],Train Loss: 0.0260, Valid Loss: 0.67024785\n",
      "Epoch [367/600],Train Loss: 0.0087, Valid Loss: 1.15654051\n",
      "Epoch [368/600],Train Loss: 0.0008, Valid Loss: 1.18167782\n",
      "Epoch [369/600],Train Loss: 0.0006, Valid Loss: 1.17506886\n",
      "Epoch [370/600],Train Loss: 0.0005, Valid Loss: 1.23137641\n",
      "Epoch [371/600],Train Loss: 0.0005, Valid Loss: 1.23467159\n",
      "Epoch [372/600],Train Loss: 0.0004, Valid Loss: 1.26282930\n",
      "Epoch [373/600],Train Loss: 0.0004, Valid Loss: 1.25487232\n",
      "Epoch [374/600],Train Loss: 0.0004, Valid Loss: 1.44975746\n",
      "Epoch [375/600],Train Loss: 0.0005, Valid Loss: 1.42256415\n",
      "Epoch [376/600],Train Loss: 0.0004, Valid Loss: 1.48828948\n",
      "Epoch [377/600],Train Loss: 0.0004, Valid Loss: 1.43065166\n",
      "Epoch [378/600],Train Loss: 0.0004, Valid Loss: 1.44455254\n",
      "Epoch [379/600],Train Loss: 0.0004, Valid Loss: 1.45884430\n",
      "Epoch [380/600],Train Loss: 0.0004, Valid Loss: 1.47436523\n",
      "Epoch [381/600],Train Loss: 0.0004, Valid Loss: 1.55591881\n",
      "Epoch [382/600],Train Loss: 0.0004, Valid Loss: 1.48748434\n",
      "Epoch [383/600],Train Loss: 0.0004, Valid Loss: 1.55676425\n",
      "Epoch [384/600],Train Loss: 0.0004, Valid Loss: 1.53145397\n",
      "Epoch [385/600],Train Loss: 0.0004, Valid Loss: 1.56537235\n",
      "Epoch [386/600],Train Loss: 0.0004, Valid Loss: 1.57288957\n",
      "Epoch [387/600],Train Loss: 0.0004, Valid Loss: 1.66073585\n",
      "Epoch [388/600],Train Loss: 0.0004, Valid Loss: 1.63774276\n",
      "Epoch [389/600],Train Loss: 0.0004, Valid Loss: 1.74232423\n",
      "Epoch [390/600],Train Loss: 0.0004, Valid Loss: 1.71878755\n",
      "Epoch [391/600],Train Loss: 0.0004, Valid Loss: 1.78047168\n",
      "Epoch [392/600],Train Loss: 0.3826, Valid Loss: 2.58189559\n",
      "Epoch [393/600],Train Loss: 0.0615, Valid Loss: 1.11356318\n",
      "Epoch [394/600],Train Loss: 0.0055, Valid Loss: 1.20821428\n",
      "Epoch [395/600],Train Loss: 0.0087, Valid Loss: 1.14476979\n",
      "Epoch [396/600],Train Loss: 0.0011, Valid Loss: 1.17757261\n",
      "Epoch [397/600],Train Loss: 0.0004, Valid Loss: 1.20259571\n",
      "Epoch [398/600],Train Loss: 0.0004, Valid Loss: 1.41422319\n",
      "Epoch [399/600],Train Loss: 0.0004, Valid Loss: 1.55526614\n",
      "Epoch [400/600],Train Loss: 0.0004, Valid Loss: 1.66280365\n",
      "Epoch [401/600],Train Loss: 0.0004, Valid Loss: 1.73483849\n",
      "Epoch [402/600],Train Loss: 0.0004, Valid Loss: 1.78171825\n",
      "Epoch [403/600],Train Loss: 0.0004, Valid Loss: 1.80121458\n",
      "Epoch [404/600],Train Loss: 0.0004, Valid Loss: 1.83158028\n",
      "Epoch [405/600],Train Loss: 0.0004, Valid Loss: 1.88709712\n",
      "Epoch [406/600],Train Loss: 0.0004, Valid Loss: 1.87267137\n",
      "Epoch [407/600],Train Loss: 0.0004, Valid Loss: 2.11878872\n",
      "Epoch [408/600],Train Loss: 0.0004, Valid Loss: 2.15606403\n",
      "Epoch [409/600],Train Loss: 0.0004, Valid Loss: 2.14245677\n",
      "Epoch [410/600],Train Loss: 0.0004, Valid Loss: 2.21265101\n",
      "Epoch [411/600],Train Loss: 0.0004, Valid Loss: 2.23834300\n",
      "Epoch [412/600],Train Loss: 0.0004, Valid Loss: 2.24260092\n",
      "Epoch [413/600],Train Loss: 0.0004, Valid Loss: 2.28821087\n",
      "Epoch [414/600],Train Loss: 0.0004, Valid Loss: 2.24545956\n",
      "Epoch [415/600],Train Loss: 0.0004, Valid Loss: 2.23339725\n",
      "Epoch [416/600],Train Loss: 0.0004, Valid Loss: 2.24645925\n",
      "Epoch [417/600],Train Loss: 0.0004, Valid Loss: 2.28592467\n",
      "Epoch [418/600],Train Loss: 0.0004, Valid Loss: 2.33000469\n",
      "Epoch [419/600],Train Loss: 0.0004, Valid Loss: 2.32109642\n",
      "Epoch [420/600],Train Loss: 0.0004, Valid Loss: 2.30939484\n",
      "Epoch [421/600],Train Loss: 0.0844, Valid Loss: 0.37248650\n",
      "Epoch [422/600],Train Loss: 0.0322, Valid Loss: 0.52307475\n",
      "Epoch [423/600],Train Loss: 0.0200, Valid Loss: 0.57789898\n",
      "Epoch [424/600],Train Loss: 0.0098, Valid Loss: 0.58927405\n",
      "Epoch [425/600],Train Loss: 0.0023, Valid Loss: 0.83255553\n",
      "Epoch [426/600],Train Loss: 0.0040, Valid Loss: 0.52130622\n",
      "Epoch [427/600],Train Loss: 0.0005, Valid Loss: 1.30119491\n",
      "Epoch [428/600],Train Loss: 0.0017, Valid Loss: 0.89986295\n",
      "Epoch [429/600],Train Loss: 0.0007, Valid Loss: 0.97030389\n",
      "Epoch [430/600],Train Loss: 0.0005, Valid Loss: 0.93976092\n",
      "Epoch [431/600],Train Loss: 0.0004, Valid Loss: 0.99966449\n",
      "Epoch [432/600],Train Loss: 0.0004, Valid Loss: 1.03296101\n",
      "Epoch [433/600],Train Loss: 0.0004, Valid Loss: 1.06183100\n",
      "Epoch [434/600],Train Loss: 0.0004, Valid Loss: 1.09244180\n",
      "Epoch [435/600],Train Loss: 0.0004, Valid Loss: 1.12059617\n",
      "Epoch [436/600],Train Loss: 0.0004, Valid Loss: 1.14961028\n",
      "Epoch [437/600],Train Loss: 0.0004, Valid Loss: 1.17750895\n",
      "Epoch [438/600],Train Loss: 0.0004, Valid Loss: 1.20721436\n",
      "Epoch [439/600],Train Loss: 0.0004, Valid Loss: 1.23448050\n",
      "Epoch [440/600],Train Loss: 0.0004, Valid Loss: 1.49634278\n",
      "Epoch [441/600],Train Loss: 0.0860, Valid Loss: 0.79875153\n",
      "Epoch [442/600],Train Loss: 0.0089, Valid Loss: 0.63166243\n",
      "Epoch [443/600],Train Loss: 0.0099, Valid Loss: 0.99502152\n",
      "Epoch [444/600],Train Loss: 0.0024, Valid Loss: 0.47687826\n",
      "Epoch [445/600],Train Loss: 0.0008, Valid Loss: 0.78035945\n",
      "Epoch [446/600],Train Loss: 0.0004, Valid Loss: 0.81194454\n",
      "Epoch [447/600],Train Loss: 0.0004, Valid Loss: 0.83723140\n",
      "Epoch [448/600],Train Loss: 0.0004, Valid Loss: 0.85793376\n",
      "Epoch [449/600],Train Loss: 0.0004, Valid Loss: 0.87600607\n",
      "Epoch [450/600],Train Loss: 0.0004, Valid Loss: 0.87685680\n",
      "Epoch [451/600],Train Loss: 0.0004, Valid Loss: 0.89407367\n",
      "Epoch [452/600],Train Loss: 0.0004, Valid Loss: 0.90982890\n",
      "Epoch [453/600],Train Loss: 0.0004, Valid Loss: 0.92461431\n",
      "Epoch [454/600],Train Loss: 0.0004, Valid Loss: 0.93853313\n",
      "Epoch [455/600],Train Loss: 0.0004, Valid Loss: 0.94887799\n",
      "Epoch [456/600],Train Loss: 0.0004, Valid Loss: 0.96495676\n",
      "Epoch [457/600],Train Loss: 0.0004, Valid Loss: 0.97935486\n",
      "Epoch [458/600],Train Loss: 0.0004, Valid Loss: 0.99335241\n",
      "Epoch [459/600],Train Loss: 0.0004, Valid Loss: 1.00736058\n",
      "Epoch [460/600],Train Loss: 0.0004, Valid Loss: 1.02432430\n",
      "Epoch [461/600],Train Loss: 0.0257, Valid Loss: 0.76296788\n",
      "Epoch [462/600],Train Loss: 0.0742, Valid Loss: 0.36964360\n",
      "Epoch [463/600],Train Loss: 0.0254, Valid Loss: 0.63484257\n",
      "Epoch [464/600],Train Loss: 0.0025, Valid Loss: 1.53335607\n",
      "Epoch [465/600],Train Loss: 0.0027, Valid Loss: 1.46582866\n",
      "Epoch [466/600],Train Loss: 0.0007, Valid Loss: 1.07102883\n",
      "Epoch [467/600],Train Loss: 0.0004, Valid Loss: 1.18507600\n",
      "Epoch [468/600],Train Loss: 0.0004, Valid Loss: 1.23363042\n",
      "Epoch [469/600],Train Loss: 0.0004, Valid Loss: 1.27154028\n",
      "Epoch [470/600],Train Loss: 0.0004, Valid Loss: 1.30235994\n",
      "Epoch [471/600],Train Loss: 0.0004, Valid Loss: 1.33030689\n",
      "Epoch [472/600],Train Loss: 0.0004, Valid Loss: 1.35607195\n",
      "Epoch [473/600],Train Loss: 0.0004, Valid Loss: 1.38245571\n",
      "Epoch [474/600],Train Loss: 0.0004, Valid Loss: 1.40555346\n",
      "Epoch [475/600],Train Loss: 0.0004, Valid Loss: 1.42449093\n",
      "Epoch [476/600],Train Loss: 0.0004, Valid Loss: 1.44011652\n",
      "Epoch [477/600],Train Loss: 0.0005, Valid Loss: 1.57519221\n",
      "Epoch [478/600],Train Loss: 0.0004, Valid Loss: 1.44138801\n",
      "Epoch [479/600],Train Loss: 0.0004, Valid Loss: 1.60478055\n",
      "Epoch [480/600],Train Loss: 0.0004, Valid Loss: 1.63050222\n",
      "Epoch [481/600],Train Loss: 0.0004, Valid Loss: 1.66058528\n",
      "Epoch [482/600],Train Loss: 0.0004, Valid Loss: 1.68100607\n",
      "Epoch [483/600],Train Loss: 0.0004, Valid Loss: 1.69711792\n",
      "Epoch [484/600],Train Loss: 0.0004, Valid Loss: 1.71106362\n",
      "Epoch [485/600],Train Loss: 0.0004, Valid Loss: 1.72352219\n",
      "Epoch [486/600],Train Loss: 0.0004, Valid Loss: 1.73548234\n",
      "Epoch [487/600],Train Loss: 0.0004, Valid Loss: 1.74677885\n",
      "Epoch [488/600],Train Loss: 0.0004, Valid Loss: 1.75829566\n",
      "Epoch [489/600],Train Loss: 0.0004, Valid Loss: 1.76956308\n",
      "Epoch [490/600],Train Loss: 0.0004, Valid Loss: 1.78029358\n",
      "Epoch [491/600],Train Loss: 0.0004, Valid Loss: 1.79117942\n",
      "Epoch [492/600],Train Loss: 0.0004, Valid Loss: 1.80216098\n",
      "Epoch [493/600],Train Loss: 0.0004, Valid Loss: 1.81271648\n",
      "Epoch [494/600],Train Loss: 0.0004, Valid Loss: 1.82293272\n",
      "Epoch [495/600],Train Loss: 0.0004, Valid Loss: 1.83317089\n",
      "Epoch [496/600],Train Loss: 0.0004, Valid Loss: 1.84318066\n",
      "Epoch [497/600],Train Loss: 0.0004, Valid Loss: 1.85321879\n",
      "Epoch [498/600],Train Loss: 0.0004, Valid Loss: 1.86288238\n",
      "Epoch [499/600],Train Loss: 0.0004, Valid Loss: 1.87244892\n",
      "Epoch [500/600],Train Loss: 0.0004, Valid Loss: 1.88198578\n",
      "Epoch [501/600],Train Loss: 0.2355, Valid Loss: 0.88295132\n",
      "Epoch [502/600],Train Loss: 0.0326, Valid Loss: 0.80746144\n",
      "Epoch [503/600],Train Loss: 0.0057, Valid Loss: 0.74346131\n",
      "Epoch [504/600],Train Loss: 0.0013, Valid Loss: 1.01248467\n",
      "Epoch [505/600],Train Loss: 0.0008, Valid Loss: 1.07540154\n",
      "Epoch [506/600],Train Loss: 0.0012, Valid Loss: 0.97611707\n",
      "Epoch [507/600],Train Loss: 0.0005, Valid Loss: 1.00762141\n",
      "Epoch [508/600],Train Loss: 0.0005, Valid Loss: 1.01653826\n",
      "Epoch [509/600],Train Loss: 0.0004, Valid Loss: 1.05492270\n",
      "Epoch [510/600],Train Loss: 0.0004, Valid Loss: 1.08531404\n",
      "Epoch [511/600],Train Loss: 0.0004, Valid Loss: 1.11423278\n",
      "Epoch [512/600],Train Loss: 0.0004, Valid Loss: 1.14003873\n",
      "Epoch [513/600],Train Loss: 0.0004, Valid Loss: 1.16383672\n",
      "Epoch [514/600],Train Loss: 0.0004, Valid Loss: 1.58167303\n",
      "Epoch [515/600],Train Loss: 0.0231, Valid Loss: 1.01551366\n",
      "Epoch [516/600],Train Loss: 0.0010, Valid Loss: 1.07349169\n",
      "Epoch [517/600],Train Loss: 0.0006, Valid Loss: 1.54189134\n",
      "Epoch [518/600],Train Loss: 0.0009, Valid Loss: 1.48912179\n",
      "Epoch [519/600],Train Loss: 0.0008, Valid Loss: 1.84159279\n",
      "Epoch [520/600],Train Loss: 0.0370, Valid Loss: 2.01158786\n",
      "Epoch [521/600],Train Loss: 0.0023, Valid Loss: 1.83785582\n",
      "Epoch [522/600],Train Loss: 0.0247, Valid Loss: 0.43472695\n",
      "Epoch [523/600],Train Loss: 0.0022, Valid Loss: 0.66566283\n",
      "Epoch [524/600],Train Loss: 0.0006, Valid Loss: 0.67528361\n",
      "Epoch [525/600],Train Loss: 0.0004, Valid Loss: 0.73280686\n",
      "Epoch [526/600],Train Loss: 0.0004, Valid Loss: 0.76242924\n",
      "Epoch [527/600],Train Loss: 0.0004, Valid Loss: 0.81599361\n",
      "Epoch [528/600],Train Loss: 0.0060, Valid Loss: 0.63568431\n",
      "Epoch [529/600],Train Loss: 0.0006, Valid Loss: 0.88572210\n",
      "Epoch [530/600],Train Loss: 0.0004, Valid Loss: 0.96709633\n",
      "Epoch [531/600],Train Loss: 0.0004, Valid Loss: 1.00257492\n",
      "Epoch [532/600],Train Loss: 0.0004, Valid Loss: 1.03141499\n",
      "Epoch [533/600],Train Loss: 0.0004, Valid Loss: 1.05494511\n",
      "Epoch [534/600],Train Loss: 0.0004, Valid Loss: 1.26758325\n",
      "Epoch [535/600],Train Loss: 0.0004, Valid Loss: 1.28779602\n",
      "Epoch [536/600],Train Loss: 0.0004, Valid Loss: 1.30663919\n",
      "Epoch [537/600],Train Loss: 0.0004, Valid Loss: 1.32393718\n",
      "Epoch [538/600],Train Loss: 0.0004, Valid Loss: 1.34224474\n",
      "Epoch [539/600],Train Loss: 0.0004, Valid Loss: 1.35502851\n",
      "Epoch [540/600],Train Loss: 0.0004, Valid Loss: 1.37417769\n",
      "Epoch [541/600],Train Loss: 0.4036, Valid Loss: 0.99203235\n",
      "Epoch [542/600],Train Loss: 0.0322, Valid Loss: 0.76470709\n",
      "Epoch [543/600],Train Loss: 0.0058, Valid Loss: 0.97065306\n",
      "Epoch [544/600],Train Loss: 0.0077, Valid Loss: 0.88089442\n",
      "Epoch [545/600],Train Loss: 0.0029, Valid Loss: 0.94152480\n",
      "Epoch [546/600],Train Loss: 0.0044, Valid Loss: 1.99670696\n",
      "Epoch [547/600],Train Loss: 0.0049, Valid Loss: 1.85478354\n",
      "Epoch [548/600],Train Loss: 0.0014, Valid Loss: 1.35933363\n",
      "Epoch [549/600],Train Loss: 0.0004, Valid Loss: 1.42819834\n",
      "Epoch [550/600],Train Loss: 0.0004, Valid Loss: 1.48588252\n",
      "Epoch [551/600],Train Loss: 0.0004, Valid Loss: 1.53460956\n",
      "Epoch [552/600],Train Loss: 0.0004, Valid Loss: 1.58256674\n",
      "Epoch [553/600],Train Loss: 0.0004, Valid Loss: 1.62662196\n",
      "Epoch [554/600],Train Loss: 0.0004, Valid Loss: 1.66454077\n",
      "Epoch [555/600],Train Loss: 0.0004, Valid Loss: 1.70055389\n",
      "Epoch [556/600],Train Loss: 0.0004, Valid Loss: 1.73568630\n",
      "Epoch [557/600],Train Loss: 0.0004, Valid Loss: 1.76753640\n",
      "Epoch [558/600],Train Loss: 0.0004, Valid Loss: 1.79907131\n",
      "Epoch [559/600],Train Loss: 0.0004, Valid Loss: 1.82879806\n",
      "Epoch [560/600],Train Loss: 0.0004, Valid Loss: 1.85806596\n",
      "Epoch [561/600],Train Loss: 0.0004, Valid Loss: 1.88569450\n",
      "Epoch [562/600],Train Loss: 0.0004, Valid Loss: 1.91091025\n",
      "Epoch [563/600],Train Loss: 0.0004, Valid Loss: 1.93564320\n",
      "Epoch [564/600],Train Loss: 0.0004, Valid Loss: 1.95991015\n",
      "Epoch [565/600],Train Loss: 0.0004, Valid Loss: 1.98292458\n",
      "Epoch [566/600],Train Loss: 0.0004, Valid Loss: 2.00956488\n",
      "Epoch [567/600],Train Loss: 0.0004, Valid Loss: 2.03657460\n",
      "Epoch [568/600],Train Loss: 0.0004, Valid Loss: 2.06220126\n",
      "Epoch [569/600],Train Loss: 0.0004, Valid Loss: 2.08706093\n",
      "Epoch [570/600],Train Loss: 0.0004, Valid Loss: 2.11351252\n",
      "Epoch [571/600],Train Loss: 0.7911, Valid Loss: 0.35772362\n",
      "Epoch [572/600],Train Loss: 0.0496, Valid Loss: 0.50174505\n",
      "Epoch [573/600],Train Loss: 0.0062, Valid Loss: 0.61163735\n",
      "Epoch [574/600],Train Loss: 0.0012, Valid Loss: 0.65210092\n",
      "Epoch [575/600],Train Loss: 0.0007, Valid Loss: 0.68497729\n",
      "Epoch [576/600],Train Loss: 0.0006, Valid Loss: 0.70328307\n",
      "Epoch [577/600],Train Loss: 0.0005, Valid Loss: 0.72054750\n",
      "Epoch [578/600],Train Loss: 0.0005, Valid Loss: 0.73092061\n",
      "Epoch [579/600],Train Loss: 0.0006, Valid Loss: 0.74433035\n",
      "Epoch [580/600],Train Loss: 0.0005, Valid Loss: 0.75988513\n",
      "Epoch [581/600],Train Loss: 0.0005, Valid Loss: 0.77591878\n",
      "Epoch [582/600],Train Loss: 0.0005, Valid Loss: 0.79592621\n",
      "Epoch [583/600],Train Loss: 0.0005, Valid Loss: 0.81827235\n",
      "Epoch [584/600],Train Loss: 0.0005, Valid Loss: 0.85110044\n",
      "Epoch [585/600],Train Loss: 0.0005, Valid Loss: 0.88285291\n",
      "Epoch [586/600],Train Loss: 0.0005, Valid Loss: 1.10381377\n",
      "Epoch [587/600],Train Loss: 0.0456, Valid Loss: 0.31972268\n",
      "Epoch [588/600],Train Loss: 0.0021, Valid Loss: 0.86452115\n",
      "Epoch [589/600],Train Loss: 0.0038, Valid Loss: 0.90937150\n",
      "Epoch [590/600],Train Loss: 0.0005, Valid Loss: 0.98195660\n",
      "Epoch [591/600],Train Loss: 0.0004, Valid Loss: 0.98655677\n",
      "Epoch [592/600],Train Loss: 0.0004, Valid Loss: 0.99851984\n",
      "Epoch [593/600],Train Loss: 0.0009, Valid Loss: 0.94732314\n",
      "Epoch [594/600],Train Loss: 0.0006, Valid Loss: 0.94275129\n",
      "Epoch [595/600],Train Loss: 0.0004, Valid Loss: 0.96665680\n",
      "Epoch [596/600],Train Loss: 0.0005, Valid Loss: 0.95517433\n",
      "Epoch [597/600],Train Loss: 0.0004, Valid Loss: 0.97768664\n",
      "Epoch [598/600],Train Loss: 0.0004, Valid Loss: 0.99381751\n",
      "Epoch [599/600],Train Loss: 0.0004, Valid Loss: 1.00860536\n",
      "Epoch [600/600],Train Loss: 0.0004, Valid Loss: 1.02011359\n",
      "Finished Training Procedure\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "binary_classifier = CNN_Classifier().cuda()\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(binary_classifier.parameters(), lr = 6e-4)\n",
    "num_epochs = 600\n",
    "save_path = '/home/ambarish/Documents/2IMN30 ML IND/calibration/models/binary_classification_model.pt'\n",
    "obtained_train_loss, obtained_val_loss, obtained_train_acc, obtained_val_acc = train(binary_classifier, train_dataloader_binary, val_dataloader_binary,\n",
    "                                        num_epochs, criterion, 10, device, save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d89d4352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Training Accuracy of the Model is 83.62419128417969\n",
      "The Validation Accuracy of the Model is 83.97015380859375\n"
     ]
    }
   ],
   "source": [
    "#Calculating the accuracy by :- summing the obtained acc on each batch / no of datapoints\n",
    "\n",
    "training_accuracy = sum(obtained_train_acc)/len(obtained_train_acc)\n",
    "validation_accuracy = sum(obtained_val_acc)/len(obtained_val_acc)\n",
    "\n",
    "print(f'The Training Accuracy of the Model is {training_accuracy}')\n",
    "print(f'The Validation Accuracy of the Model is {validation_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff8447f",
   "metadata": {},
   "source": [
    "#### Step 1\n",
    "\n",
    "Choose a metric for evaluating the classifier's generalization performance and assign your choice to a string variable `classifier_metric_choice`. Motivate the choice (including the hyper-parameters, if any) in a string variable `classifier_metric_motivation` (max 800 characters). Describe how you decide based on this metric if a classifier is sufficiently calibrated in a string variable `classifier_metric_decision` (max 200 characters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ddb1c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#// BEGIN_TODO [STEP_1] Choose a classifier metric (5 points)\n",
    "\n",
    "# ===== =====> Replace this line by your code. <===== ===== #\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a25860f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#// END_TODO [STEP_1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f555f2",
   "metadata": {},
   "source": [
    "#### Step 2\n",
    "\n",
    "Train a binary classifier on the training set `X_train` and `y_train`. You are free to chose any model and data preprocessing method, as long as:\n",
    "\n",
    "- your classifier outputs the predicted class (0 or 1) and the confidence estimate of the positive class,\n",
    "- your submission executes within 10 minutes on Momotor,\n",
    "- you use the libraries available on Momotor (if you would like to use other libraries, please contact the instructor to see if it can be accommodated).\n",
    "\n",
    "Evaluate your trained model on the test set `X_test` and `y_test`. What do you observe? How do you know that your model is well trained? Assign your answer to a string variable `observation_classifier` (max 600 characters).\n",
    "\n",
    "Apply the classifier to the `X_test` data and store the predicted classes and confidence estimate in the variables `uncalibrated_y` and `uncalibrated_p`, respectively:\n",
    "\n",
    "- `uncalibrated_y` should be a `np.ndarray` of shape $[N,]$ and `dtype` of `np.int32`, where $N$ is the number of samples and each value is the predicted class,\n",
    "- `uncalibrated_p` should be a `np.ndarray` of shape $[N,]$ and `dtype` of `np.float32`, where each value is the classifier's confidence in the positive class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074a3c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#// BEGIN_TODO [STEP_2] Train a binary classifier (10 points)\n",
    "\n",
    "# ===== =====> Replace this line by your code. <===== ===== #\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291017db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#// END_TODO [STEP_2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654c3caa",
   "metadata": {},
   "source": [
    "## Measure and visualize calibration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336c9fcc",
   "metadata": {},
   "source": [
    "#### Step 3\n",
    "\n",
    "Visualize the calibration of your trained model using a reliability diagram. Describe your observations in the variable `observation_uncalibrated` (max 1000 characters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ba83de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#// BEGIN_TODO [STEP_3] Visualize calibration of uncalibrated model (5 points)\n",
    "\n",
    "# ===== =====> Replace this line by your code. <===== ===== #\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd674c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#// END_TODO [STEP_3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6bbb64",
   "metadata": {},
   "source": [
    "#### Step 4\n",
    "\n",
    "Choose a calibration metric and assign its name to a string variable `binary_metric_choice`. Motivate the choice (including the hyper-parameters, if any) in a string variable `binary_metric_motivation` (max 800 characters). Describe how you decide based on this metric if a classifier is sufficiently calibrated in a string variable `binary_metric_decision` (max 200 characters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae00973",
   "metadata": {},
   "outputs": [],
   "source": [
    "#// BEGIN_TODO [STEP_4] Choose a calibration metric (5 points)\n",
    "\n",
    "# ===== =====> Replace this line by your code. <===== ===== #\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc913ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#// END_TODO [STEP_4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01295925",
   "metadata": {},
   "source": [
    "#### Step 5\n",
    "\n",
    "Implement the chosen calibration metric. It should be a Python class with the following method:\n",
    "\n",
    "- `score(self, p, y)`, where\n",
    "    - `p` is an `np.ndarray` of shape $[N,]$ with the confidence estimates of the *positive class* for $N$ samples.\n",
    "    - `y` is an `np.ndarray` of shape $[N,]$ with the corresponding true labels (0 or 1).\n",
    "    - It returns a `np.float` number with the calibration error.\n",
    "\n",
    "Instantiate the class (setting any relevant hyper-parameters) and assign it to the variable `binary_metric`.\n",
    "\n",
    "Measure the calibration error of your model on `X_test` and `y_test` and assign the result to the variable `binary_uncalibrated`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a820dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#// BEGIN_TODO [STEP_5] Implement the calibration metric (5 points)\n",
    "\n",
    "# ===== =====> Replace this line by your code. <===== ===== #\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97bac44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#// END_TODO [STEP_5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e1b7b9",
   "metadata": {},
   "source": [
    "## Calibrate the classifer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1276d99d",
   "metadata": {},
   "source": [
    "#### Step 6\n",
    "\n",
    "Implement at least two calibration methods. Each calibration method should be a Python class with the following methods:\n",
    "\n",
    "- `fit(self, p, y)`, where \n",
    "    - `p` is an `np.ndarray` of shape $[N,]$ with the confidence estimates of the *positive class* for $N$ samples.\n",
    "    - `y` is an `np.ndarray` of shape $[N,]$ with the corresponding true labels (0 or 1).\n",
    "    - It fits the calibration model and returns a reference to `self`.\n",
    "- `predict_proba(self, p)`, where\n",
    "    - `p` is an `np.ndarray` of shape $[N,]$ with confidence estimates of the *positive class* for $N$ samples.\n",
    "    - It returns an `np.ndarray` of shape $[N,]$ with the calibrated confidence estimates for each sample in `p`.\n",
    "\n",
    "> **IMPORTANT:** You are not allowed to use the `sklearn.calibration.CalibratedClassifierCV()` method.\n",
    "\n",
    "Instantiate the calibration methods (setting any relevant hyper-parameters) and assign them to a list variable `binary_calibrators`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42dd91c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#// BEGIN_TODO [STEP_6] Implement calibration methods (10 points)\n",
    "\n",
    "# ===== =====> Replace this line by your code. <===== ===== #\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bdb6d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#// END_TODO [STEP_6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03c78a9",
   "metadata": {},
   "source": [
    "#### Step 7\n",
    "\n",
    "Evaluate the performance of your calibration methods. Describe your observations in the variable `observation_calibrators` (max 2000 characters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fac6439",
   "metadata": {},
   "outputs": [],
   "source": [
    "#// BEGIN_TODO [STEP_7] Evaluate the calibration method (10 points)\n",
    "\n",
    "# ===== =====> Replace this line by your code. <===== ===== #\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c84a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#// END_TODO [STEP_7]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17787b13",
   "metadata": {},
   "source": [
    "#### Step 8\n",
    "\n",
    "Let's evaluate your selected calibration method on the output from different classifier, stored in the `./data/wafer_calibration.pkl` pickle file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5394811a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/wafer_calibration.pkl', 'rb') as f:\n",
    "    p_calib_train, p_calib_test, y_calib_train, y_calib_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f5e369",
   "metadata": {},
   "source": [
    "`p_calib_train` and `p_calib_test` contain the confidence estimates of a classifier (divided into a training and test set), and `y_calib_train` and `y_calib_test` contain the corresponding true labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8978bf59",
   "metadata": {},
   "source": [
    "Retrain your calibration methods on `p_calib_train` and `y_calib_train`. Use `p_calib_test` and `y_calib_test` to evaluate your methods. Describe your observations in the variable `observation_other` (max 800 characters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc63ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#// BEGIN_TODO [STEP_8] Evaluate the calibration method on another classifier (5 points)\n",
    "\n",
    "# ===== =====> Replace this line by your code. <===== ===== #\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9220eaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#// END_TODO [STEP_8]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6315f3aa",
   "metadata": {},
   "source": [
    "#### Step 9\n",
    "\n",
    "Choose your favorite calibration method. Assign the instantiated class implementing your chosen calibration method to the variable `binary_calibrator` and its name to a string variable `binary_calibrator_choice`. Motivate the choice (including hyper-parameters, if any) in a string variable `binary_calibrator_motivation` (max 800 characters).\n",
    "\n",
    "Apply the chosen calibration method to your model on the test data `X_test` and assign the calibrated confidence estimates to `q_test` (an `np.ndarray` of shape $[N,]$ and `dtype` of `np.float32`).\n",
    "\n",
    "Apply the calibration method to the confidence estimates in `p_calib_test` and assign the calibrated class probabilities to the variable `q_calib_test` (an `np.ndarray` of shape $[N,]$ and `dtype` of `np.float32`).\n",
    "\n",
    "Measure the calibration error of the calibrated model and assign the result to the variable `binary_calibrated`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1df57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#// BEGIN_TODO [STEP_9] Choose a calibration method (5 points)\n",
    "\n",
    "# ===== =====> Replace this line by your code. <===== ===== #\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b07200",
   "metadata": {},
   "outputs": [],
   "source": [
    "#// END_TODO [STEP_9]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f1abf0",
   "metadata": {},
   "source": [
    "#### Leaderboard\n",
    "\n",
    "If you would like to see how your binary calibration method compares to others, you can chose to submit your calibration method to the leaderboard. All submitted calibration methods will be evaluated on a held-out set from a similar distribution as `p_calib_test` and `y_calib_test`.\n",
    "\n",
    "You may submit your notebook as many times as you like before the deadline. We will try to update the leaderboard daily. Your latest submission at the moment the leaderboard is computed will count. \n",
    "\n",
    "If you would like to submit your `binary_calibrator` to the leaderboard, then assign a reference to your *trained* calibration method to the variable `leaderboard_calibrator`. Otherwise, set it to `None`. Since it will be evaluated on a held-out set, you are free to use any data that was included with this assignment. Also, assign a nickname to the string variable `leaderboard_nickname` that will be shown on the leaderboard next to your score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c808ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#// BEGIN_TODO [LEADERBOARD] Join the leaderboard (0 points)\n",
    "\n",
    "# ===== =====> Replace this line by your code. <===== ===== #\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f28249",
   "metadata": {},
   "outputs": [],
   "source": [
    "#// END_TODO [LEADERBOARD]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10219b1",
   "metadata": {},
   "source": [
    "## Extend to multi-class classification\n",
    "\n",
    "So far we have assumed a binary classification task. In this part you will implement a calibration metric and method that is applicable to multi-class classification.\n",
    "\n",
    "#### Step 10\n",
    "\n",
    "For evaluating the multi-class calibration metric and method, train a classifier on the multi-class wafer map data `X_train` and `y_train` that was loaded earlier. You are free to chose any model and data preprocessing method, as long as:\n",
    "\n",
    "- your classifier outputs the predicted class and the confidence estimate for each class,\n",
    "- your submission executes within 10 minutes on Momotor,\n",
    "- you use the libraries available on Momotor (if you would like to use other libraries, please contact the instructor to see if it can be accommodated).\n",
    "\n",
    "Evaluate your trained model on the test set `X_test` and `y_test`. What do you observe? How do you know that your model is well trained? Assign your answer to a string variable `observation_multiclass_classifier` (max 600 characters).\n",
    "\n",
    "Apply the classifier to the `X_test` data and store the predicted classes and confidence estimates in the variables `multi_uncalibrated_y` and `multi_uncalibrated_p`, respectively:\n",
    "\n",
    "- `multi_uncalibrated_y` should be a `np.ndarray` of shape $[N,K]$, with the predicted classes (one-hot encoded), where $N$ is the number of samples and $K$ is the number of classes, i.e. `multi_uncalibrated_y[n][k]` is 1 if the classifier predicted class `k`, otherwise it is 0, \n",
    "- `multi_uncalibrated_p` should be a `np.ndarray` of shape $[N,K]$, with the corresponding confidence estimates, i.e. `multi_uncalibrated_p[n][k]` is the classifier's confidence that the predicted class should be `k`.\n",
    "\n",
    "> **IMPORTANT:** For the wafer dataset $K = 9$ and the class indeces should correspond to the classes listed in section **Load the data**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4561cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#// BEGIN_TODO [STEP_10] Train a multi-class classifier (10 points)\n",
    "\n",
    "# ===== =====> Replace this line by your code. <===== ===== #\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71968ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "#// END_TODO [STEP_10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57c9607",
   "metadata": {},
   "source": [
    "#### Step 11\n",
    "\n",
    "Choose a calibration metric and assign your choice to a string variable `multi_calibration_choice`. Motivate the choice (including the hyper-parameters, if any) in a string variable `multi_calibration_motivation` (max 800 characters). Describe how you decide based on this metric if a classifier is sufficiently calibrated in a string variable `multi_calibration_decision` (max 200 characters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4079883a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#// BEGIN_TODO [STEP_11] Choose a multi-class calibration metric (5 points)\n",
    "\n",
    "# ===== =====> Replace this line by your code. <===== ===== #\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfa35ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#// END_TODO [STEP_11]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27153f2c",
   "metadata": {},
   "source": [
    "#### Step 12\n",
    "\n",
    "Implement the chosen calibration metric. It should be a Python class with the following method:\n",
    "\n",
    "- `score(self, p, y)`, where\n",
    "    - `p` is a `np.ndarray` of shape $[N,K]$ with the confidence estimates, where $N$ is the number of samples and $K$ is the number of classes,\n",
    "    - `y` is a `np.ndarray` of shape $[N,K]$ with the corresponding true class labels (one-hot encoded)\n",
    "    - It returns a `np.float` number with the calibration error.\n",
    "\n",
    "Instantiate the class (setting any relevant hyper-parameters) and assign it to the variable `multi_metric`.\n",
    "\n",
    "Measure the calibration error of your model on `X_test` and `y_test` and assign the result to the variable `multi_uncalibrated`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb587e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#// BEGIN_TODO [STEP_12] Implement the multi-class calibration metric (5 points)\n",
    "\n",
    "# ===== =====> Replace this line by your code. <===== ===== #\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90c41e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#// END_TODO [STEP_12]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41bb2fb",
   "metadata": {},
   "source": [
    "#### Step 13\n",
    "\n",
    "Implement at least one calibration method. Each calibration method should be a Python class with the following methods:\n",
    "\n",
    "- `fit(self, p, labels)`: where \n",
    "    - `p` is a `np.ndarray` of shape $[N,K]$ with the confidence estimates, where $N$ is the number of samples and $K$ is the number of classes,\n",
    "    - `y` is a `np.ndarray` of shape $[N,K]$ with the corresponding true class labels (one-hot encoded)\n",
    "    - It fits the calibration model and returns a reference to `self`.\n",
    "\n",
    "- `predict_proba(self, p)`: where\n",
    "    - `p` is a `np.ndarray` of shape $[N,K]$ with the confidence estimates, where $N$ is the number of samples and $K$ is the number of classes,\n",
    "    - It returns an `np.ndarray` of shape $[N,K]$ with the calibrated confidence estimates for each sample in `p`.\n",
    "\n",
    "> **IMPORTANT:** You are not allowed to use the `sklearn.calibration.CalibratedClassifierCV()` method.\n",
    "\n",
    "Instantiate the calibration methods (setting any relevant hyper-parameters) and assign them to a list variable `multi_calibrators`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e5cb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#// BEGIN_TODO [STEP_13] Implement multi-class calibration methods (10 points)\n",
    "\n",
    "# ===== =====> Replace this line by your code. <===== ===== #\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81430a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#// END_TODO [STEP_13]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7a2430",
   "metadata": {},
   "source": [
    "#### Step 14\n",
    "\n",
    "Evaluate the performance of your calibration methods. Choose your favorite method and assign its name to a string variable `multiclass_calibrator_choice`. Motivate the choice (including hyper-parameters, if any) in a string variable `multiclass_calibrator_motivation` (max 800 characters).\n",
    "\n",
    "Apply the chosen calibration method to your model on the test data `X_test` and assign the calibrated confidence estimates to `q_multi_test` (an `np.ndarray` of shape $[N,K]$ and `dtype` of `np.float32`).\n",
    "\n",
    "Measure the calibration error of the calibrated model and assign the result to the variable `multi_calibrated`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12713a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#// BEGIN_TODO [STEP_14] Choose a multi-class calibration method (5 points)\n",
    "\n",
    "# ===== =====> Replace this line by your code. <===== ===== #\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ab922c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#// END_TODO [STEP_14]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c227cdb",
   "metadata": {},
   "source": [
    "#### Step 15\n",
    "\n",
    "A well calibrated classifier can also be used to identify whether a test sample is out-of-distribution, i.e. if it is very different from the data that the classifier was trained on. The `ood.pkl` file contains several out-of-distribution samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3e8e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/ood.pkl', 'rb') as f:\n",
    "    X_ood = pickle.load(f)\n",
    "    \n",
    "plt.imshow(X_ood[0]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55702d57",
   "metadata": {},
   "source": [
    "Evaluate your classifier and calibration method on the data in `X_ood`. Describe your observations in a string variable `observation_ood` (max 1000 characters). Describe one drawback of this approach for identifying out-of-distribution samples in a string variable `drawback_ood` (max 500 characters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fc53a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#// BEGIN_TODO [STEP_15] (5 points)\n",
    "\n",
    "# ===== =====> Replace this line by your code. <===== ===== #\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e64c875",
   "metadata": {},
   "outputs": [],
   "source": [
    "#// END_TODO [STEP_15]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c1e555",
   "metadata": {},
   "source": [
    "# Feedback\n",
    "\n",
    "Please fill in this questionaire to help us improve this course for the next year. Your feedback will be anonymized and will not affect your grade in any way!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4323869",
   "metadata": {},
   "source": [
    "### How many hours did you spend on this assignment?\n",
    "\n",
    "Assign a number to variable `feedback_time`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e209271",
   "metadata": {},
   "outputs": [],
   "source": [
    "#// BEGIN_FEEDBACK [Feedback_1] (0 points)\n",
    "\n",
    "#// END_FEEDBACK [Feedback_1]\n",
    "\n",
    "import numbers\n",
    "assert isinstance(feedback_time, numbers.Number), \"Please assign a number to variable feedback_time\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92df9e1a",
   "metadata": {},
   "source": [
    "### How difficult did you find this assignment?\n",
    "\n",
    "Assign an integer to variable `feedback_difficulty`, on a scale 0 - 10, with 0 being very easy, 5 being just right, and 10 being very difficult."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44da128",
   "metadata": {},
   "outputs": [],
   "source": [
    "#// BEGIN_FEEDBACK [Feedback_2] (0 points)\n",
    "\n",
    "#// END_FEEDBACK [Feedback_2]\n",
    "\n",
    "assert isinstance(feedback_difficulty, numbers.Number), \"Please assign a number to variable feedback_difficulty\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3968bde4",
   "metadata": {},
   "source": [
    "### Which Machine Learning-related courses did you complete (TUE/workshop/online/etc.)?\n",
    "\n",
    "Assign a string to variable `feedback_courses`, listing any ML courses you followed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b570b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#// BEGIN_FEEDBACK [Feedback_3] (0 points)\n",
    "\n",
    "#// END_FEEDBACK [Feedback_3]\n",
    "\n",
    "assert isinstance(feedback_courses, str), \"Please assign a string to variable feedback_courses\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ca5959",
   "metadata": {},
   "source": [
    "### Would you prefer to earn points for the leaderboard exercise?\n",
    "\n",
    "Currently, the leaderboard exercise is optional: your participation on the leaderboard does not affect your grade, neither does your position on the leaderboard. Would you enjoy a leaderboard exercise, where each group's score is published on the leaderboard and the winning group gets a reward (e.g. they get a 10 for the entire assignment, all other groups are assessed normally on the other exercises)?\n",
    "\n",
    "Assign a number to variable `feedback_leaderboard`:\n",
    "\n",
    "- 1 for \"yes, I would like it\"\n",
    "- 0 for \"I do not have an opinion\"\n",
    "- -1 for \"no, I prefer an optional leaderboard\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc30d31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#// BEGIN_FEEDBACK [Feedback_4] (0 points)\n",
    "\n",
    "#// END_FEEDBACK [Feedback_4]\n",
    "\n",
    "assert isinstance(feedback_leaderboard, numbers.Number), \"Please assign a number to variable feedback_leaderboard\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3790e84",
   "metadata": {},
   "source": [
    "### (Optional) What did you like?\n",
    "\n",
    "Assign a string to variable `feedback_like`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78831b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#// BEGIN_FEEDBACK [Feedback_5] (0 points)\n",
    "\n",
    "#// END_FEEDBACK [Feedback_5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b74a0b",
   "metadata": {},
   "source": [
    "### (Optional) What can be improved?\n",
    "\n",
    "Assign a string to variable `feedback_improve`. Please be specific, so that we can act on your feedback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c79c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#// BEGIN_FEEDBACK [Feedback_6] (0 points)\n",
    "\n",
    "#// END_FEEDBACK [Feedback_6]"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
